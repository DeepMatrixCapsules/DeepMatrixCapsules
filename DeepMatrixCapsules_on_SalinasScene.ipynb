{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZU9nS-J714K"
   },
   "source": [
    "# **Deep Matrix Capsules on Salinas Scene**\n",
    "### **Parameters:**\n",
    "\n",
    "WindowSize: 25\n",
    "\n",
    "No. of PCA Components: 30\n",
    "\n",
    "No. of epochs: 10\n",
    "\n",
    "Batch size: 64\n",
    "\n",
    "Learning Rate: 3e-3\n",
    "\n",
    "EM Iterations: 2\n",
    "\n",
    "Architecture: [64, 32, 16, 16, 16]\n",
    "\n",
    "Percentage of training data used: 50%\n",
    "\n",
    "Percentage of validation data: 10% \n",
    "\n",
    "Percentage of testing data: 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lo7Iv6t8c7q"
   },
   "source": [
    "## **Imports & Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyNgS4dq353c"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "from operator import truediv\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score\n",
    "\n",
    "import spectral\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRXMOdRD70RL",
    "outputId": "3f39cdaf-4638-4d34-95bd-4b013b31c395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "seed = 3\n",
    "\n",
    "# Making the model deterministic\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7hCepAWyzjQ"
   },
   "source": [
    "## **Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvmHgMALy6SQ"
   },
   "source": [
    "### Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPaayr7SVkp6"
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.8\n",
    "val_and_test_ratio = 0.5\n",
    "windowSize = 25\n",
    "batch_size = 64\n",
    "no_of_PCA_components = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx16jdZty2lL"
   },
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtR6i2Df4eIg"
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "A, B, C, D = 64, 32, 16, 16\n",
    "\n",
    "# EM Iterations\n",
    "em_iters = 2\n",
    "\n",
    "# PCA Componenets\n",
    "pca_components = 30\n",
    "\n",
    "# Epochs\n",
    "epochs = 10\n",
    "\n",
    "# Learning rate\n",
    "lr = 3e-3\n",
    "\n",
    "# Weight Decay\n",
    "wd = 2e-7\n",
    "\n",
    "# Test Intervals\n",
    "test_intervals = 1\n",
    "\n",
    "# Log Interval\n",
    "log_interval = 10\n",
    "\n",
    "# No. of classes\n",
    "num_class = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeXpt6io3znQ"
   },
   "source": [
    "## **Loading Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cowVRmhKVe3B"
   },
   "source": [
    "#### Defining Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhxVJKj8Vohj"
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    images = sio.loadmat('Data/Salinas/Salinas.mat')['salinas_corrected']\n",
    "    labels = sio.loadmat('Data/Salinas/Salinas_gt.mat')['salinas_gt']\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkWk5WP6VqsP"
   },
   "outputs": [],
   "source": [
    "def applyPCA(X, n_components=no_of_PCA_components, seed=seed):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=seed)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0], X.shape[1], n_components))\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUMwqDrtVs0F"
   },
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2*margin, X.shape[1] + 2*margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX [x_offset : X.shape[0] + x_offset, y_offset : X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcj3-RsNVuvl"
   },
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=windowSize, removeZeroLabels=True):\n",
    "    margin = int((windowSize-1)/2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    \n",
    "    patchesData = np.zeros((X.shape[0]*X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    \n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin: r + margin + 1, c - margin:c + margin + 1]\n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex += 1\n",
    "\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels > 0, :, :, :]\n",
    "        patchesLabels = patchesLabels[patchesLabels > 0]\n",
    "        patchesLabels -= 1\n",
    "    \n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zPDW-7XVxXl"
   },
   "outputs": [],
   "source": [
    "def dataSplit(X, y, val_and_test_ratio=val_and_test_ratio, test_ratio=test_ratio, random_state=seed):\n",
    "    X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=val_and_test_ratio, random_state=random_state, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=test_ratio, random_state=random_state, stratify=y_val_and_test)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyxuQV9OV0LS"
   },
   "outputs": [],
   "source": [
    "def convertToDataloader(X_train, y_train, X_val, y_val, X_test, y_test, batch_size=batch_size, K=no_of_PCA_components):\n",
    "\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    y_train = torch.Tensor(y_train)\n",
    "    X_val = torch.Tensor(X_val)\n",
    "    y_val = torch.Tensor(y_val)\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_test = torch.Tensor(y_test)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQNIH-ClV26m"
   },
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3X-GTxKV2qx"
   },
   "outputs": [],
   "source": [
    "X, y = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AS6ZWMX5V6gI"
   },
   "outputs": [],
   "source": [
    "X = applyPCA(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rglm_OIV9Nl"
   },
   "outputs": [],
   "source": [
    "X, y = createImageCubes(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Ez4Ls8V_If"
   },
   "outputs": [],
   "source": [
    "X = X.transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVCEEFM6WAvs"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = dataSplit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9E56ZwIWC6R"
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = convertToDataloader(X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mw6iBRJpWETi"
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'valid': val_loader,'test': test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D_5INAM4u33"
   },
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBmkAG3_43c-"
   },
   "source": [
    "#### Capsule Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp1hds7dy_9v"
   },
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \n",
    "    def __init__(self, A=32, B=32, K=1, P=4, stride=1):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.pose = nn.Conv2d(in_channels=A, out_channels=B*P*P,\n",
    "                            kernel_size=K, stride=stride, bias=True)\n",
    "        self.a = nn.Conv2d(in_channels=A, out_channels=B,\n",
    "                            kernel_size=K, stride=stride, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = self.pose(x)\n",
    "        a = self.a(x)\n",
    "        a = self.sigmoid(a)\n",
    "        out = torch.cat([p, a], dim=1)\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey4FeNfp42l7"
   },
   "outputs": [],
   "source": [
    "class ConvCaps(nn.Module):\n",
    "\n",
    "    def __init__(self, B=32, C=32, K=3, P=4, stride=2, iters=3,\n",
    "                 coor_add=False, w_shared=False):\n",
    "        super(ConvCaps, self).__init__()\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.psize = P*P\n",
    "        self.stride = stride\n",
    "        self.iters = iters\n",
    "        self.coor_add = coor_add\n",
    "        self.w_shared = w_shared\n",
    "        self.eps = 1e-8\n",
    "        self._lambda = 1e-03\n",
    "        self.ln_2pi = torch.cuda.FloatTensor(1).fill_(math.log(2*math.pi))\n",
    "\n",
    "        self.beta_u = nn.Parameter(torch.zeros(C))\n",
    "        self.beta_a = nn.Parameter(torch.zeros(C))\n",
    "\n",
    "        self.weights = nn.Parameter(torch.randn(1, K*K*B, C, P, P))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def m_step(self, a_in, r, v, eps, b, B, C, psize):\n",
    "\n",
    "        r = r * a_in\n",
    "        r = r / (r.sum(dim=2, keepdim=True) + eps)\n",
    "        r_sum = r.sum(dim=1, keepdim=True)\n",
    "        coeff = r / (r_sum + eps)\n",
    "        coeff = coeff.view(b, B, C, 1)\n",
    "\n",
    "        mu = torch.sum(coeff * v, dim=1, keepdim=True)\n",
    "        sigma_sq = torch.sum(coeff * (v - mu)**2, dim=1, keepdim=True) + eps\n",
    "\n",
    "        r_sum = r_sum.view(b, C, 1)\n",
    "        sigma_sq = sigma_sq.view(b, C, psize)\n",
    "        cost_h = (self.beta_u.view(C, 1) + torch.log(sigma_sq.sqrt())) * r_sum\n",
    "\n",
    "        a_out = self.sigmoid(self._lambda*(self.beta_a - cost_h.sum(dim=2)))\n",
    "        sigma_sq = sigma_sq.view(b, 1, C, psize)\n",
    "\n",
    "        return a_out, mu, sigma_sq\n",
    "\n",
    "    def e_step(self, mu, sigma_sq, a_out, v, eps, b, C):\n",
    "\n",
    "        ln_p_j_h = -1. * (v - mu)**2 / (2 * sigma_sq) \\\n",
    "                    - torch.log(sigma_sq.sqrt()) \\\n",
    "                    - 0.5*self.ln_2pi\n",
    "\n",
    "        ln_ap = ln_p_j_h.sum(dim=3) + torch.log(a_out.view(b, 1, C))\n",
    "        r = self.softmax(ln_ap)\n",
    "        return r\n",
    "\n",
    "    def caps_em_routing(self, v, a_in, C, eps):\n",
    "\n",
    "        b, B, c, psize = v.shape\n",
    "        assert c == C\n",
    "        assert (b, B, 1) == a_in.shape\n",
    "\n",
    "        r = torch.cuda.FloatTensor(b, B, C).fill_(1./C)\n",
    "        for iter_ in range(self.iters):\n",
    "            a_out, mu, sigma_sq = self.m_step(a_in, r, v, eps, b, B, C, psize)\n",
    "            if iter_ < self.iters - 1:\n",
    "                r = self.e_step(mu, sigma_sq, a_out, v, eps, b, C)\n",
    "\n",
    "        return mu, a_out\n",
    "\n",
    "    def add_pathes(self, x, B, K, psize, stride):\n",
    "\n",
    "        b, h, w, c = x.shape\n",
    "        assert h == w\n",
    "        assert c == B*(psize+1)\n",
    "        oh = ow = int(((h - K )/stride)+ 1)\n",
    "        idxs = [[(h_idx + k_idx) \\\n",
    "                for k_idx in range(0, K)] \\\n",
    "                for h_idx in range(0, h - K + 1, stride)]\n",
    "        x = x[:, idxs, :, :]\n",
    "        x = x[:, :, :, idxs, :]\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous()\n",
    "        return x, oh, ow\n",
    "\n",
    "    def transform_view(self, x, w, C, P, w_shared=False):\n",
    "\n",
    "        b, B, psize = x.shape\n",
    "        assert psize == P*P\n",
    "\n",
    "        x = x.view(b, B, 1, P, P)\n",
    "        if w_shared:\n",
    "            hw = int(B / w.size(1))\n",
    "            w = w.repeat(1, hw, 1, 1, 1)\n",
    "\n",
    "        w = w.repeat(b, 1, 1, 1, 1)\n",
    "        x = x.repeat(1, 1, C, 1, 1)\n",
    "        v = torch.matmul(x, w)\n",
    "        v = v.view(b, B, C, P*P)\n",
    "        return v\n",
    "\n",
    "    def add_coord(self, v, b, h, w, B, C, psize):\n",
    "\n",
    "        assert h == w\n",
    "        v = v.view(b, h, w, B, C, psize)\n",
    "        coor = torch.arange(h, dtype=torch.float32) / h\n",
    "        coor_h = torch.cuda.FloatTensor(1, h, 1, 1, 1, self.psize).fill_(0.)\n",
    "        coor_w = torch.cuda.FloatTensor(1, 1, w, 1, 1, self.psize).fill_(0.)\n",
    "        coor_h[0, :, 0, 0, 0, 0] = coor\n",
    "        coor_w[0, 0, :, 0, 0, 1] = coor\n",
    "        v = v + coor_h + coor_w\n",
    "        v = v.view(b, h*w*B, C, psize)\n",
    "        return v\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, h, w, c = x.shape\n",
    "        if not self.w_shared:\n",
    "            x, oh, ow = self.add_pathes(x, self.B, self.K, self.psize, self.stride)\n",
    "\n",
    "            p_in = x[:, :, :, :, :, :self.B*self.psize].contiguous()\n",
    "            a_in = x[:, :, :, :, :, self.B*self.psize:].contiguous()\n",
    "            p_in = p_in.view(b*oh*ow, self.K*self.K*self.B, self.psize)\n",
    "            a_in = a_in.view(b*oh*ow, self.K*self.K*self.B, 1)\n",
    "            v = self.transform_view(p_in, self.weights, self.C, self.P)\n",
    "\n",
    "            p_out, a_out = self.caps_em_routing(v, a_in, self.C, self.eps)\n",
    "            p_out = p_out.view(b, oh, ow, self.C*self.psize)\n",
    "            a_out = a_out.view(b, oh, ow, self.C)\n",
    "            out = torch.cat([p_out, a_out], dim=3)\n",
    "        else:\n",
    "            assert c == self.B*(self.psize+1)\n",
    "            assert 1 == self.K\n",
    "            assert 1 == self.stride\n",
    "            p_in = x[:, :, :, :self.B*self.psize].contiguous()\n",
    "            p_in = p_in.view(b, h*w*self.B, self.psize)\n",
    "            a_in = x[:, :, :, self.B*self.psize:].contiguous()\n",
    "            a_in = a_in.view(b, h*w*self.B, 1)\n",
    "\n",
    "            v = self.transform_view(p_in, self.weights, self.C, self.P, self.w_shared)\n",
    "\n",
    "            if self.coor_add:\n",
    "                v = self.add_coord(v, b, h, w, self.B, self.C, self.psize)\n",
    "\n",
    "            _, out = self.caps_em_routing(v, a_in, self.C, self.eps)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKbBGB1FzGPw"
   },
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "\n",
    "    def __init__(self, A=32, B=32, C=32, D=32, E=10, K=3, P=4, iters=3):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=pca_components, out_channels=A,\n",
    "                               kernel_size=5, stride=2, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=A, eps=0.001,\n",
    "                                 momentum=0.1, affine=True)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.primary_caps = PrimaryCaps(A, B, 1, P, stride=1)\n",
    "        self.conv_caps1 = ConvCaps(B, C, K, P, stride=2, iters=iters)\n",
    "        self.conv_caps2 = ConvCaps(C, D, K, P, stride=1, iters=iters)\n",
    "        self.class_caps = ConvCaps(D, E, 1, P, stride=1, iters=iters,\n",
    "                                        coor_add=True, w_shared=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.primary_caps(x)\n",
    "        x = self.conv_caps1(x)\n",
    "        x = self.conv_caps2(x)\n",
    "        x = self.class_caps(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ypxKKRG5hvO"
   },
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4J7NoS985UHc"
   },
   "outputs": [],
   "source": [
    "class SpreadLoss(_Loss):\n",
    "\n",
    "    def __init__(self, m_min=0.2, m_max=0.9, num_class=9):\n",
    "        super(SpreadLoss, self).__init__()\n",
    "        self.m_min = m_min\n",
    "        self.m_max = m_max\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def forward(self, x, target, r):\n",
    "        b, E = x.shape\n",
    "        assert E == self.num_class\n",
    "        margin = self.m_min + (self.m_max - self.m_min)*r\n",
    "\n",
    "        at = torch.cuda.FloatTensor(b).fill_(0)\n",
    "        for i, a in enumerate(target):\n",
    "            lb = int(a.item())\n",
    "            at[i] = x[i][lb]\n",
    "        at = at.view(b, 1).repeat(1, E)\n",
    "\n",
    "        zeros = x.new_zeros(x.shape)\n",
    "        loss = torch.max(margin - (at - x), zeros)\n",
    "        loss = loss**2\n",
    "        loss = loss.sum() / b - margin**2\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05AZSkZ16Jxp"
   },
   "source": [
    "## **Training Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suwWgu2z6rg8"
   },
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIgNfsLi5jlU"
   },
   "outputs": [],
   "source": [
    "train_loader = dataloaders['train']\n",
    "valid_loader = dataloaders['valid']\n",
    "test_loader = dataloaders['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq1YU_XD7Cco"
   },
   "source": [
    "#### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7v8XF9M6uQR"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    y_pred = output.argmax(dim=1).float()\n",
    "    res = accuracy_score(target.to('cpu'), y_pred.to('cpu')) * 100\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvXyaGUH7HLo"
   },
   "source": [
    "#### Learning Rate Decay function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EW1wGZrS7EQA"
   },
   "outputs": [],
   "source": [
    "def exp_lr_decay(optimizer, global_step, init_lr = 3e-3, decay_steps = 20000,\n",
    "                                        decay_rate = 0.96, lr_clip = 3e-3 ,staircase=False):\n",
    "        \n",
    "    if staircase:\n",
    "        lr = (init_lr * decay_rate**(global_step // decay_steps)) \n",
    "    else:\n",
    "        lr = (init_lr * decay_rate**(global_step / decay_steps)) \n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rkhe68NX7P8p"
   },
   "source": [
    "#### Average Meter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdmfQJTt7KG8"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zWNMYc87U-4"
   },
   "source": [
    "#### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gvsb63dX7R_X"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    train_len = len(train_loader)\n",
    "    epoch_acc = 0\n",
    "    end = time.time()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        r = (1.*batch_idx + (epoch-1)*train_len) / (epochs*train_len)\n",
    "        loss = criterion(output, target, r)\n",
    "        acc = accuracy(output, target)\n",
    "        \n",
    "        global_step = (batch_idx+1) + (epoch - 1) * len(train_loader) \n",
    "        exp_lr_decay(optimizer=optimizer, global_step=global_step)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        epoch_acc += acc\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {}\\t[{}/{} ({:.0f}%)]\\t'\n",
    "                  'Loss: {:.6f}\\tAccuracy: {:.6f}\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})'.format(\n",
    "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                  100. * batch_idx / len(train_loader),\n",
    "                  loss.item(), acc,\n",
    "                  batch_time=batch_time, data_time=data_time))\n",
    "            \n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZzi5Vn27d-X"
   },
   "source": [
    "#### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49eSAz-I7dTP"
   },
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device, test=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "    test_len = len(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target, r=1).item()\n",
    "            acc += accuracy(output, target)\n",
    "\n",
    "    test_loss /= test_len\n",
    "    acc /= test_len\n",
    "    if test:\n",
    "        print('\\nTest set: Average loss: {:.6f}, Accuracy: {:.6f} \\n'.format(\n",
    "        test_loss, acc))\n",
    "    else:\n",
    "        print('\\nVal set: Average loss: {:.6f}, Accuracy: {:.6f} \\n'.format(\n",
    "            test_loss, acc))\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hRWF2apsMzc"
   },
   "source": [
    "## **Training Process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGwX3eimsZmA"
   },
   "source": [
    "#### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_YYc6YxsXZV",
    "outputId": "f249ae4b-9a9c-4e79-9e8c-a70fbd49dbcc"
   },
   "outputs": [],
   "source": [
    "model = CapsNet(A=A, B=B, C=C, D=D, E=num_class,\n",
    "                    iters=em_iters).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZwvqJ_4ZZaI"
   },
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk54JHDaZY6l",
    "outputId": "4926e901-6ead-4d4b-9d90-d03c877976d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : 64x30x5x5 = 48000\n",
      "conv1.bias : 64\n",
      "bn1.weight : 64\n",
      "bn1.bias : 64\n",
      "primary_caps.pose.weight : 512x64x1x1 = 32768\n",
      "primary_caps.pose.bias : 512\n",
      "primary_caps.a.weight : 32x64x1x1 = 2048\n",
      "primary_caps.a.bias : 32\n",
      "conv_caps1.beta_u : 16\n",
      "conv_caps1.beta_a : 16\n",
      "conv_caps1.weights : 1x288x16x4x4 = 73728\n",
      "conv_caps2.beta_u : 16\n",
      "conv_caps2.beta_a : 16\n",
      "conv_caps2.weights : 1x144x16x4x4 = 36864\n",
      "class_caps.beta_u : 16\n",
      "class_caps.beta_a : 16\n",
      "class_caps.weights : 1x16x16x4x4 = 4096\n",
      "\n",
      " Total Trainable Parameters:  198336\n"
     ]
    }
   ],
   "source": [
    "def model_summary(model):\n",
    "    total_param = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_param = np.prod(param.size())\n",
    "            if param.dim() > 1:\n",
    "                print(name, ':', 'x'.join(str(x) for x in list(param.size())), '=', num_param)\n",
    "            else:\n",
    "                print(name, ':', num_param)\n",
    "            total_param += num_param\n",
    "    print(\"\\n Total Trainable Parameters: \", total_param)\n",
    "\n",
    "model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0JocqrGZmIN"
   },
   "source": [
    "#### Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEPfkoFhZva8"
   },
   "outputs": [],
   "source": [
    "criterion = SpreadLoss(num_class=num_class, m_min=0.2, m_max=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayyIRBgr7goB",
    "outputId": "fb47dd9e-2ee5-4d93-94cc-50703a625e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 4.011412, Accuracy: 5.404412 \n",
      "\n",
      "Train Epoch: 1\t[0/27064 (0%)]\tLoss: 0.829147\tAccuracy: 7.812500\tTime 0.892 (0.892)\tData 0.009 (0.009)\n",
      "Train Epoch: 1\t[640/27064 (2%)]\tLoss: 0.044459\tAccuracy: 87.500000\tTime 0.842 (0.846)\tData 0.003 (0.004)\n",
      "Train Epoch: 1\t[1280/27064 (5%)]\tLoss: 0.009881\tAccuracy: 100.000000\tTime 0.844 (0.844)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[1920/27064 (7%)]\tLoss: 0.005047\tAccuracy: 98.437500\tTime 0.841 (0.843)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[2560/27064 (9%)]\tLoss: 0.019728\tAccuracy: 93.750000\tTime 0.839 (0.842)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[3200/27064 (12%)]\tLoss: 0.002834\tAccuracy: 100.000000\tTime 0.843 (0.842)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[3840/27064 (14%)]\tLoss: 0.005665\tAccuracy: 100.000000\tTime 0.842 (0.842)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[4480/27064 (17%)]\tLoss: 0.004538\tAccuracy: 96.875000\tTime 0.845 (0.843)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[5120/27064 (19%)]\tLoss: 0.001910\tAccuracy: 100.000000\tTime 0.847 (0.843)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[5760/27064 (21%)]\tLoss: 0.002380\tAccuracy: 100.000000\tTime 0.849 (0.844)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[6400/27064 (24%)]\tLoss: 0.002154\tAccuracy: 100.000000\tTime 0.849 (0.844)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[7040/27064 (26%)]\tLoss: 0.003370\tAccuracy: 100.000000\tTime 0.850 (0.845)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[7680/27064 (28%)]\tLoss: 0.001577\tAccuracy: 100.000000\tTime 0.852 (0.845)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[8320/27064 (31%)]\tLoss: 0.002898\tAccuracy: 98.437500\tTime 0.851 (0.846)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[8960/27064 (33%)]\tLoss: 0.001181\tAccuracy: 100.000000\tTime 0.853 (0.846)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[9600/27064 (35%)]\tLoss: 0.003739\tAccuracy: 100.000000\tTime 0.853 (0.847)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[10240/27064 (38%)]\tLoss: 0.001439\tAccuracy: 100.000000\tTime 0.853 (0.847)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[10880/27064 (40%)]\tLoss: 0.000763\tAccuracy: 100.000000\tTime 0.853 (0.847)\tData 0.003 (0.003)\n",
      "Train Epoch: 1\t[11520/27064 (43%)]\tLoss: 0.002837\tAccuracy: 100.000000\tTime 0.859 (0.848)\tData 0.003 (0.004)\n",
      "Train Epoch: 1\t[12160/27064 (45%)]\tLoss: 0.000582\tAccuracy: 100.000000\tTime 0.862 (0.849)\tData 0.003 (0.004)\n",
      "Train Epoch: 1\t[12800/27064 (47%)]\tLoss: 0.000526\tAccuracy: 100.000000\tTime 0.868 (0.850)\tData 0.003 (0.004)\n",
      "Train Epoch: 1\t[13440/27064 (50%)]\tLoss: 0.000893\tAccuracy: 100.000000\tTime 0.864 (0.851)\tData 0.003 (0.004)\n",
      "Train Epoch: 1\t[14080/27064 (52%)]\tLoss: 0.008772\tAccuracy: 96.875000\tTime 0.860 (0.851)\tData 0.003 (0.004)\n",
      "Train Epoch: 1\t[14720/27064 (54%)]\tLoss: 0.000367\tAccuracy: 100.000000\tTime 0.858 (0.852)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[15360/27064 (57%)]\tLoss: 0.006458\tAccuracy: 98.437500\tTime 0.858 (0.852)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[16000/27064 (59%)]\tLoss: 0.002091\tAccuracy: 100.000000\tTime 0.858 (0.853)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[16640/27064 (61%)]\tLoss: 0.000753\tAccuracy: 100.000000\tTime 0.859 (0.853)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[17280/27064 (64%)]\tLoss: 0.011907\tAccuracy: 96.875000\tTime 0.858 (0.853)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[17920/27064 (66%)]\tLoss: 0.002912\tAccuracy: 100.000000\tTime 0.858 (0.854)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[18560/27064 (69%)]\tLoss: 0.000324\tAccuracy: 100.000000\tTime 0.858 (0.854)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[19200/27064 (71%)]\tLoss: 0.000257\tAccuracy: 100.000000\tTime 0.858 (0.854)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[19840/27064 (73%)]\tLoss: 0.002639\tAccuracy: 98.437500\tTime 0.862 (0.854)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[20480/27064 (76%)]\tLoss: 0.003023\tAccuracy: 98.437500\tTime 0.859 (0.855)\tData 0.003 (0.005)\n",
      "Train Epoch: 1\t[21120/27064 (78%)]\tLoss: 0.001462\tAccuracy: 100.000000\tTime 0.859 (0.855)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[21760/27064 (80%)]\tLoss: 0.000409\tAccuracy: 100.000000\tTime 0.860 (0.855)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[22400/27064 (83%)]\tLoss: 0.001122\tAccuracy: 100.000000\tTime 0.856 (0.855)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[23040/27064 (85%)]\tLoss: 0.000149\tAccuracy: 100.000000\tTime 0.857 (0.856)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[23680/27064 (87%)]\tLoss: 0.000597\tAccuracy: 100.000000\tTime 0.860 (0.856)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[24320/27064 (90%)]\tLoss: 0.000108\tAccuracy: 100.000000\tTime 0.856 (0.856)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[24960/27064 (92%)]\tLoss: 0.000525\tAccuracy: 100.000000\tTime 0.863 (0.856)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[25600/27064 (95%)]\tLoss: 0.002565\tAccuracy: 98.437500\tTime 0.860 (0.856)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[26240/27064 (97%)]\tLoss: 0.006113\tAccuracy: 98.437500\tTime 0.858 (0.856)\tData 0.003 (0.006)\n",
      "Train Epoch: 1\t[26880/27064 (99%)]\tLoss: 0.001875\tAccuracy: 100.000000\tTime 0.858 (0.857)\tData 0.003 (0.006)\n",
      "\n",
      "Val set: Average loss: 0.261924, Accuracy: 99.926471 \n",
      "\n",
      "-------------------- HIGHEST ACCURACY ---------------------------\n",
      "Train Epoch: 2\t[0/27064 (0%)]\tLoss: 0.000365\tAccuracy: 100.000000\tTime 0.855 (0.855)\tData 0.004 (0.004)\n",
      "Train Epoch: 2\t[640/27064 (2%)]\tLoss: 0.000707\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[1280/27064 (5%)]\tLoss: 0.000355\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[1920/27064 (7%)]\tLoss: 0.001286\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[2560/27064 (9%)]\tLoss: 0.000709\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[3200/27064 (12%)]\tLoss: 0.000634\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[3840/27064 (14%)]\tLoss: 0.002067\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.013 (0.007)\n",
      "Train Epoch: 2\t[4480/27064 (17%)]\tLoss: 0.000780\tAccuracy: 100.000000\tTime 0.868 (0.861)\tData 0.016 (0.007)\n",
      "Train Epoch: 2\t[5120/27064 (19%)]\tLoss: 0.001100\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[5760/27064 (21%)]\tLoss: 0.000056\tAccuracy: 100.000000\tTime 0.868 (0.861)\tData 0.017 (0.007)\n",
      "Train Epoch: 2\t[6400/27064 (24%)]\tLoss: 0.001327\tAccuracy: 98.437500\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[7040/27064 (26%)]\tLoss: 0.000185\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[7680/27064 (28%)]\tLoss: 0.000260\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[8320/27064 (31%)]\tLoss: 0.000268\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[8960/27064 (33%)]\tLoss: 0.000164\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[9600/27064 (35%)]\tLoss: 0.004094\tAccuracy: 98.437500\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[10240/27064 (38%)]\tLoss: 0.000066\tAccuracy: 100.000000\tTime 0.861 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[10880/27064 (40%)]\tLoss: 0.000289\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[11520/27064 (43%)]\tLoss: 0.001080\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[12160/27064 (45%)]\tLoss: 0.000236\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[12800/27064 (47%)]\tLoss: 0.001098\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[13440/27064 (50%)]\tLoss: 0.000049\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[14080/27064 (52%)]\tLoss: 0.000258\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[14720/27064 (54%)]\tLoss: 0.000751\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[15360/27064 (57%)]\tLoss: 0.000255\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[16000/27064 (59%)]\tLoss: 0.000172\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[16640/27064 (61%)]\tLoss: 0.000236\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[17280/27064 (64%)]\tLoss: 0.000023\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[17920/27064 (66%)]\tLoss: 0.000050\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[18560/27064 (69%)]\tLoss: 0.000603\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[19200/27064 (71%)]\tLoss: 0.000433\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[19840/27064 (73%)]\tLoss: 0.000093\tAccuracy: 100.000000\tTime 0.867 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[20480/27064 (76%)]\tLoss: 0.000084\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[21120/27064 (78%)]\tLoss: 0.001756\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[21760/27064 (80%)]\tLoss: 0.000493\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[22400/27064 (83%)]\tLoss: 0.000885\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[23040/27064 (85%)]\tLoss: 0.000002\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[23680/27064 (87%)]\tLoss: 0.012995\tAccuracy: 96.875000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[24320/27064 (90%)]\tLoss: 0.000402\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[24960/27064 (92%)]\tLoss: 0.000058\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[25600/27064 (95%)]\tLoss: 0.000232\tAccuracy: 100.000000\tTime 0.867 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 2\t[26240/27064 (97%)]\tLoss: 0.000013\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 2\t[26880/27064 (99%)]\tLoss: 0.000003\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.189145, Accuracy: 99.944853 \n",
      "\n",
      "-------------------- HIGHEST ACCURACY ---------------------------\n",
      "Train Epoch: 3\t[0/27064 (0%)]\tLoss: 0.000832\tAccuracy: 100.000000\tTime 0.858 (0.858)\tData 0.005 (0.005)\n",
      "Train Epoch: 3\t[640/27064 (2%)]\tLoss: 0.000767\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[1280/27064 (5%)]\tLoss: 0.005618\tAccuracy: 98.437500\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[1920/27064 (7%)]\tLoss: 0.000600\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[2560/27064 (9%)]\tLoss: 0.000242\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[3200/27064 (12%)]\tLoss: 0.000375\tAccuracy: 100.000000\tTime 0.862 (0.860)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[3840/27064 (14%)]\tLoss: 0.001036\tAccuracy: 100.000000\tTime 0.864 (0.860)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[4480/27064 (17%)]\tLoss: 0.000356\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[5120/27064 (19%)]\tLoss: 0.001065\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[5760/27064 (21%)]\tLoss: 0.000017\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[6400/27064 (24%)]\tLoss: 0.000012\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[7040/27064 (26%)]\tLoss: 0.001371\tAccuracy: 100.000000\tTime 0.861 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[7680/27064 (28%)]\tLoss: 0.000650\tAccuracy: 100.000000\tTime 0.867 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[8320/27064 (31%)]\tLoss: 0.000212\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[8960/27064 (33%)]\tLoss: 0.000055\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[9600/27064 (35%)]\tLoss: 0.000182\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[10240/27064 (38%)]\tLoss: 0.000036\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[10880/27064 (40%)]\tLoss: 0.000684\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[11520/27064 (43%)]\tLoss: 0.000129\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[12160/27064 (45%)]\tLoss: 0.000801\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.014 (0.007)\n",
      "Train Epoch: 3\t[12800/27064 (47%)]\tLoss: 0.000437\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[13440/27064 (50%)]\tLoss: 0.000290\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.014 (0.007)\n",
      "Train Epoch: 3\t[14080/27064 (52%)]\tLoss: 0.000478\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[14720/27064 (54%)]\tLoss: 0.003270\tAccuracy: 98.437500\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[15360/27064 (57%)]\tLoss: 0.002820\tAccuracy: 98.437500\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[16000/27064 (59%)]\tLoss: 0.001553\tAccuracy: 100.000000\tTime 0.867 (0.861)\tData 0.016 (0.007)\n",
      "Train Epoch: 3\t[16640/27064 (61%)]\tLoss: 0.000026\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[17280/27064 (64%)]\tLoss: 0.000282\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[17920/27064 (66%)]\tLoss: 0.000252\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[18560/27064 (69%)]\tLoss: 0.001108\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[19200/27064 (71%)]\tLoss: 0.001279\tAccuracy: 100.000000\tTime 0.868 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[19840/27064 (73%)]\tLoss: 0.000136\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[20480/27064 (76%)]\tLoss: 0.000172\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[21120/27064 (78%)]\tLoss: 0.000494\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[21760/27064 (80%)]\tLoss: 0.000398\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[22400/27064 (83%)]\tLoss: 0.001494\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[23040/27064 (85%)]\tLoss: 0.000195\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 3\t[23680/27064 (87%)]\tLoss: 0.000319\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[24320/27064 (90%)]\tLoss: 0.001753\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 3\t[24960/27064 (92%)]\tLoss: 0.000341\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.008)\n",
      "Train Epoch: 3\t[25600/27064 (95%)]\tLoss: 0.000910\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.008)\n",
      "Train Epoch: 3\t[26240/27064 (97%)]\tLoss: 0.003645\tAccuracy: 98.437500\tTime 0.862 (0.861)\tData 0.011 (0.008)\n",
      "Train Epoch: 3\t[26880/27064 (99%)]\tLoss: 0.000875\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.008)\n",
      "\n",
      "Val set: Average loss: 0.131215, Accuracy: 99.944853 \n",
      "\n",
      "Train Epoch: 4\t[0/27064 (0%)]\tLoss: 0.000044\tAccuracy: 100.000000\tTime 0.860 (0.860)\tData 0.006 (0.006)\n",
      "Train Epoch: 4\t[640/27064 (2%)]\tLoss: 0.000451\tAccuracy: 100.000000\tTime 0.866 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[1280/27064 (5%)]\tLoss: 0.000810\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[1920/27064 (7%)]\tLoss: 0.000122\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[2560/27064 (9%)]\tLoss: 0.000775\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[3200/27064 (12%)]\tLoss: 0.000341\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[3840/27064 (14%)]\tLoss: 0.000395\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[4480/27064 (17%)]\tLoss: 0.000252\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[5120/27064 (19%)]\tLoss: 0.000341\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[5760/27064 (21%)]\tLoss: 0.000200\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[6400/27064 (24%)]\tLoss: 0.000267\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[7040/27064 (26%)]\tLoss: 0.000279\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[7680/27064 (28%)]\tLoss: 0.001635\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[8320/27064 (31%)]\tLoss: 0.000139\tAccuracy: 100.000000\tTime 0.862 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[8960/27064 (33%)]\tLoss: 0.000997\tAccuracy: 100.000000\tTime 0.861 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[9600/27064 (35%)]\tLoss: 0.000697\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[10240/27064 (38%)]\tLoss: 0.000371\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[10880/27064 (40%)]\tLoss: 0.002050\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.013 (0.007)\n",
      "Train Epoch: 4\t[11520/27064 (43%)]\tLoss: 0.000474\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[12160/27064 (45%)]\tLoss: 0.000372\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[12800/27064 (47%)]\tLoss: 0.001260\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[13440/27064 (50%)]\tLoss: 0.000151\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[14080/27064 (52%)]\tLoss: 0.000646\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[14720/27064 (54%)]\tLoss: 0.000114\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[15360/27064 (57%)]\tLoss: 0.003246\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[16000/27064 (59%)]\tLoss: 0.001024\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[16640/27064 (61%)]\tLoss: 0.000000\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[17280/27064 (64%)]\tLoss: 0.003243\tAccuracy: 98.437500\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[17920/27064 (66%)]\tLoss: 0.000508\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[18560/27064 (69%)]\tLoss: 0.000350\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.014 (0.007)\n",
      "Train Epoch: 4\t[19200/27064 (71%)]\tLoss: 0.000155\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[19840/27064 (73%)]\tLoss: 0.000162\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[20480/27064 (76%)]\tLoss: 0.000371\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[21120/27064 (78%)]\tLoss: 0.000976\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[21760/27064 (80%)]\tLoss: 0.000212\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[22400/27064 (83%)]\tLoss: 0.001814\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 4\t[23040/27064 (85%)]\tLoss: 0.000023\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[23680/27064 (87%)]\tLoss: 0.000052\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[24320/27064 (90%)]\tLoss: 0.000455\tAccuracy: 100.000000\tTime 0.868 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[24960/27064 (92%)]\tLoss: 0.000594\tAccuracy: 100.000000\tTime 0.883 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[25600/27064 (95%)]\tLoss: 0.000064\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[26240/27064 (97%)]\tLoss: 0.000393\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 4\t[26880/27064 (99%)]\tLoss: 0.000097\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.096373, Accuracy: 99.981618 \n",
      "\n",
      "-------------------- HIGHEST ACCURACY ---------------------------\n",
      "Train Epoch: 5\t[0/27064 (0%)]\tLoss: 0.000018\tAccuracy: 100.000000\tTime 0.858 (0.858)\tData 0.005 (0.005)\n",
      "Train Epoch: 5\t[640/27064 (2%)]\tLoss: 0.000025\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[1280/27064 (5%)]\tLoss: 0.000005\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[1920/27064 (7%)]\tLoss: 0.000409\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[2560/27064 (9%)]\tLoss: 0.000654\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[3200/27064 (12%)]\tLoss: 0.000334\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.014 (0.007)\n",
      "Train Epoch: 5\t[3840/27064 (14%)]\tLoss: 0.000757\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[4480/27064 (17%)]\tLoss: 0.001195\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[5120/27064 (19%)]\tLoss: 0.000275\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[5760/27064 (21%)]\tLoss: 0.000047\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.013 (0.007)\n",
      "Train Epoch: 5\t[6400/27064 (24%)]\tLoss: 0.000320\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[7040/27064 (26%)]\tLoss: 0.012006\tAccuracy: 96.875000\tTime 0.866 (0.861)\tData 0.013 (0.007)\n",
      "Train Epoch: 5\t[7680/27064 (28%)]\tLoss: 0.003837\tAccuracy: 100.000000\tTime 0.867 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[8320/27064 (31%)]\tLoss: 0.000510\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[8960/27064 (33%)]\tLoss: 0.000884\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[9600/27064 (35%)]\tLoss: 0.000546\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[10240/27064 (38%)]\tLoss: 0.000064\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[10880/27064 (40%)]\tLoss: 0.003419\tAccuracy: 98.437500\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[11520/27064 (43%)]\tLoss: 0.001963\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[12160/27064 (45%)]\tLoss: 0.000611\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[12800/27064 (47%)]\tLoss: 0.000203\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[13440/27064 (50%)]\tLoss: 0.034074\tAccuracy: 85.937500\tTime 0.868 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[14080/27064 (52%)]\tLoss: 0.010567\tAccuracy: 98.437500\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[14720/27064 (54%)]\tLoss: 0.001487\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[15360/27064 (57%)]\tLoss: 0.008309\tAccuracy: 98.437500\tTime 0.868 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[16000/27064 (59%)]\tLoss: 0.000189\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[16640/27064 (61%)]\tLoss: 0.008872\tAccuracy: 98.437500\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[17280/27064 (64%)]\tLoss: 0.000777\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[17920/27064 (66%)]\tLoss: 0.000960\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[18560/27064 (69%)]\tLoss: 0.000081\tAccuracy: 100.000000\tTime 0.869 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[19200/27064 (71%)]\tLoss: 0.000513\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[19840/27064 (73%)]\tLoss: 0.002899\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[20480/27064 (76%)]\tLoss: 0.000415\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.014 (0.007)\n",
      "Train Epoch: 5\t[21120/27064 (78%)]\tLoss: 0.000244\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[21760/27064 (80%)]\tLoss: 0.000043\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[22400/27064 (83%)]\tLoss: 0.000084\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[23040/27064 (85%)]\tLoss: 0.000018\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[23680/27064 (87%)]\tLoss: 0.001068\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[24320/27064 (90%)]\tLoss: 0.000321\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[24960/27064 (92%)]\tLoss: 0.000512\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 5\t[25600/27064 (95%)]\tLoss: 0.001550\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.013 (0.007)\n",
      "Train Epoch: 5\t[26240/27064 (97%)]\tLoss: 0.000691\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 5\t[26880/27064 (99%)]\tLoss: 0.001226\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.058299, Accuracy: 99.981618 \n",
      "\n",
      "Train Epoch: 6\t[0/27064 (0%)]\tLoss: 0.000682\tAccuracy: 100.000000\tTime 0.861 (0.861)\tData 0.006 (0.006)\n",
      "Train Epoch: 6\t[640/27064 (2%)]\tLoss: 0.000037\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[1280/27064 (5%)]\tLoss: 0.000161\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[1920/27064 (7%)]\tLoss: 0.000055\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[2560/27064 (9%)]\tLoss: 0.006803\tAccuracy: 98.437500\tTime 0.866 (0.861)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[3200/27064 (12%)]\tLoss: 0.000898\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[3840/27064 (14%)]\tLoss: 0.023578\tAccuracy: 92.187500\tTime 0.866 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[4480/27064 (17%)]\tLoss: 0.009796\tAccuracy: 98.437500\tTime 0.868 (0.862)\tData 0.013 (0.007)\n",
      "Train Epoch: 6\t[5120/27064 (19%)]\tLoss: 0.001496\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[5760/27064 (21%)]\tLoss: 0.001240\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[6400/27064 (24%)]\tLoss: 0.003346\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[7040/27064 (26%)]\tLoss: 0.000268\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[7680/27064 (28%)]\tLoss: 0.002694\tAccuracy: 98.437500\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[8320/27064 (31%)]\tLoss: 0.003973\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[8960/27064 (33%)]\tLoss: 0.009076\tAccuracy: 98.437500\tTime 0.862 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[9600/27064 (35%)]\tLoss: 0.000147\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[10240/27064 (38%)]\tLoss: 0.016364\tAccuracy: 96.875000\tTime 0.865 (0.862)\tData 0.013 (0.007)\n",
      "Train Epoch: 6\t[10880/27064 (40%)]\tLoss: 0.001787\tAccuracy: 100.000000\tTime 0.868 (0.862)\tData 0.013 (0.007)\n",
      "Train Epoch: 6\t[11520/27064 (43%)]\tLoss: 0.002435\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[12160/27064 (45%)]\tLoss: 0.002874\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[12800/27064 (47%)]\tLoss: 0.001171\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[13440/27064 (50%)]\tLoss: 0.000406\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[14080/27064 (52%)]\tLoss: 0.001319\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[14720/27064 (54%)]\tLoss: 0.000217\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[15360/27064 (57%)]\tLoss: 0.000239\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[16000/27064 (59%)]\tLoss: 0.000248\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[16640/27064 (61%)]\tLoss: 0.000233\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[17280/27064 (64%)]\tLoss: 0.000154\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[17920/27064 (66%)]\tLoss: 0.000154\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[18560/27064 (69%)]\tLoss: 0.000028\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[19200/27064 (71%)]\tLoss: 0.000035\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[19840/27064 (73%)]\tLoss: 0.000259\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[20480/27064 (76%)]\tLoss: 0.000470\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[21120/27064 (78%)]\tLoss: 0.000563\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[21760/27064 (80%)]\tLoss: 0.000065\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[22400/27064 (83%)]\tLoss: 0.002116\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[23040/27064 (85%)]\tLoss: 0.000594\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[23680/27064 (87%)]\tLoss: 0.000015\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[24320/27064 (90%)]\tLoss: 0.000027\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 6\t[24960/27064 (92%)]\tLoss: 0.000648\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[25600/27064 (95%)]\tLoss: 0.000097\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[26240/27064 (97%)]\tLoss: 0.000125\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 6\t[26880/27064 (99%)]\tLoss: 0.000684\tAccuracy: 100.000000\tTime 0.861 (0.862)\tData 0.011 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.033900, Accuracy: 99.981618 \n",
      "\n",
      "Train Epoch: 7\t[0/27064 (0%)]\tLoss: 0.000082\tAccuracy: 100.000000\tTime 0.862 (0.862)\tData 0.006 (0.006)\n",
      "Train Epoch: 7\t[640/27064 (2%)]\tLoss: 0.000293\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[1280/27064 (5%)]\tLoss: 0.000191\tAccuracy: 100.000000\tTime 0.863 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[1920/27064 (7%)]\tLoss: 0.000539\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[2560/27064 (9%)]\tLoss: 0.000283\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[3200/27064 (12%)]\tLoss: 0.000450\tAccuracy: 100.000000\tTime 0.865 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[3840/27064 (14%)]\tLoss: 0.000052\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[4480/27064 (17%)]\tLoss: 0.000164\tAccuracy: 100.000000\tTime 0.864 (0.861)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[5120/27064 (19%)]\tLoss: 0.000375\tAccuracy: 100.000000\tTime 0.866 (0.861)\tData 0.013 (0.007)\n",
      "Train Epoch: 7\t[5760/27064 (21%)]\tLoss: 0.000519\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[6400/27064 (24%)]\tLoss: 0.000949\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[7040/27064 (26%)]\tLoss: 0.000396\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[7680/27064 (28%)]\tLoss: 0.011708\tAccuracy: 98.437500\tTime 0.862 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[8320/27064 (31%)]\tLoss: 0.004651\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[8960/27064 (33%)]\tLoss: 0.002744\tAccuracy: 100.000000\tTime 0.872 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[9600/27064 (35%)]\tLoss: 0.003176\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[10240/27064 (38%)]\tLoss: 0.000916\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[10880/27064 (40%)]\tLoss: 0.001544\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[11520/27064 (43%)]\tLoss: 0.001483\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[12160/27064 (45%)]\tLoss: 0.000456\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[12800/27064 (47%)]\tLoss: 0.000086\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[13440/27064 (50%)]\tLoss: 0.000440\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[14080/27064 (52%)]\tLoss: 0.005117\tAccuracy: 98.437500\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[14720/27064 (54%)]\tLoss: 0.001156\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[15360/27064 (57%)]\tLoss: 0.000704\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[16000/27064 (59%)]\tLoss: 0.001327\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[16640/27064 (61%)]\tLoss: 0.000451\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[17280/27064 (64%)]\tLoss: 0.000364\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[17920/27064 (66%)]\tLoss: 0.001499\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[18560/27064 (69%)]\tLoss: 0.000574\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[19200/27064 (71%)]\tLoss: 0.000062\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[19840/27064 (73%)]\tLoss: 0.000003\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[20480/27064 (76%)]\tLoss: 0.000986\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[21120/27064 (78%)]\tLoss: 0.000207\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[21760/27064 (80%)]\tLoss: 0.000845\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[22400/27064 (83%)]\tLoss: 0.003754\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[23040/27064 (85%)]\tLoss: 0.000585\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 7\t[23680/27064 (87%)]\tLoss: 0.000617\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[24320/27064 (90%)]\tLoss: 0.004137\tAccuracy: 100.000000\tTime 0.869 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[24960/27064 (92%)]\tLoss: 0.001320\tAccuracy: 100.000000\tTime 0.868 (0.862)\tData 0.015 (0.007)\n",
      "Train Epoch: 7\t[25600/27064 (95%)]\tLoss: 0.000273\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[26240/27064 (97%)]\tLoss: 0.001527\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 7\t[26880/27064 (99%)]\tLoss: 0.000367\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.023785, Accuracy: 100.000000 \n",
      "\n",
      "-------------------- HIGHEST ACCURACY ---------------------------\n",
      "Train Epoch: 8\t[0/27064 (0%)]\tLoss: 0.004184\tAccuracy: 100.000000\tTime 0.857 (0.857)\tData 0.004 (0.004)\n",
      "Train Epoch: 8\t[640/27064 (2%)]\tLoss: 0.000610\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[1280/27064 (5%)]\tLoss: 0.000824\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[1920/27064 (7%)]\tLoss: 0.000337\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[2560/27064 (9%)]\tLoss: 0.000158\tAccuracy: 100.000000\tTime 0.862 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[3200/27064 (12%)]\tLoss: 0.000032\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[3840/27064 (14%)]\tLoss: 0.000248\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[4480/27064 (17%)]\tLoss: 0.000572\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[5120/27064 (19%)]\tLoss: 0.000017\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[5760/27064 (21%)]\tLoss: 0.000331\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[6400/27064 (24%)]\tLoss: 0.000050\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[7040/27064 (26%)]\tLoss: 0.003036\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[7680/27064 (28%)]\tLoss: 0.000331\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[8320/27064 (31%)]\tLoss: 0.000996\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[8960/27064 (33%)]\tLoss: 0.000098\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[9600/27064 (35%)]\tLoss: 0.000009\tAccuracy: 100.000000\tTime 0.863 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[10240/27064 (38%)]\tLoss: 0.000260\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[10880/27064 (40%)]\tLoss: 0.000026\tAccuracy: 100.000000\tTime 0.862 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[11520/27064 (43%)]\tLoss: 0.000100\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[12160/27064 (45%)]\tLoss: 0.000962\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[12800/27064 (47%)]\tLoss: 0.000311\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[13440/27064 (50%)]\tLoss: 0.000032\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[14080/27064 (52%)]\tLoss: 0.000298\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[14720/27064 (54%)]\tLoss: 0.000192\tAccuracy: 100.000000\tTime 0.864 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[15360/27064 (57%)]\tLoss: 0.000131\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[16000/27064 (59%)]\tLoss: 0.000623\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[16640/27064 (61%)]\tLoss: 0.001600\tAccuracy: 100.000000\tTime 0.868 (0.862)\tData 0.013 (0.007)\n",
      "Train Epoch: 8\t[17280/27064 (64%)]\tLoss: 0.001035\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[17920/27064 (66%)]\tLoss: 0.000904\tAccuracy: 100.000000\tTime 0.868 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[18560/27064 (69%)]\tLoss: 0.000726\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.013 (0.007)\n",
      "Train Epoch: 8\t[19200/27064 (71%)]\tLoss: 0.007608\tAccuracy: 100.000000\tTime 0.866 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[19840/27064 (73%)]\tLoss: 0.000772\tAccuracy: 100.000000\tTime 0.867 (0.862)\tData 0.014 (0.007)\n",
      "Train Epoch: 8\t[20480/27064 (76%)]\tLoss: 0.001789\tAccuracy: 100.000000\tTime 0.865 (0.862)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[21120/27064 (78%)]\tLoss: 0.000437\tAccuracy: 100.000000\tTime 0.871 (0.862)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[21760/27064 (80%)]\tLoss: 0.001769\tAccuracy: 100.000000\tTime 0.868 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[22400/27064 (83%)]\tLoss: 0.000747\tAccuracy: 100.000000\tTime 0.868 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[23040/27064 (85%)]\tLoss: 0.000719\tAccuracy: 100.000000\tTime 0.865 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[23680/27064 (87%)]\tLoss: 0.001384\tAccuracy: 100.000000\tTime 0.868 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[24320/27064 (90%)]\tLoss: 0.000221\tAccuracy: 100.000000\tTime 0.864 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[24960/27064 (92%)]\tLoss: 0.000684\tAccuracy: 100.000000\tTime 0.866 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[25600/27064 (95%)]\tLoss: 0.000480\tAccuracy: 100.000000\tTime 0.865 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 8\t[26240/27064 (97%)]\tLoss: 0.000295\tAccuracy: 100.000000\tTime 0.867 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 8\t[26880/27064 (99%)]\tLoss: 0.000138\tAccuracy: 100.000000\tTime 0.866 (0.863)\tData 0.011 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.011271, Accuracy: 100.000000 \n",
      "\n",
      "Train Epoch: 9\t[0/27064 (0%)]\tLoss: 0.000913\tAccuracy: 100.000000\tTime 0.863 (0.863)\tData 0.006 (0.006)\n",
      "Train Epoch: 9\t[640/27064 (2%)]\tLoss: 0.000421\tAccuracy: 100.000000\tTime 0.867 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[1280/27064 (5%)]\tLoss: 0.000160\tAccuracy: 100.000000\tTime 0.869 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[1920/27064 (7%)]\tLoss: 0.000084\tAccuracy: 100.000000\tTime 0.865 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[2560/27064 (9%)]\tLoss: 0.000173\tAccuracy: 100.000000\tTime 0.866 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[3200/27064 (12%)]\tLoss: 0.000080\tAccuracy: 100.000000\tTime 0.864 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[3840/27064 (14%)]\tLoss: 0.000082\tAccuracy: 100.000000\tTime 0.864 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[4480/27064 (17%)]\tLoss: 0.000276\tAccuracy: 100.000000\tTime 0.867 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[5120/27064 (19%)]\tLoss: 0.001291\tAccuracy: 100.000000\tTime 0.870 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[5760/27064 (21%)]\tLoss: 0.001450\tAccuracy: 100.000000\tTime 0.866 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[6400/27064 (24%)]\tLoss: 0.000906\tAccuracy: 100.000000\tTime 0.865 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[7040/27064 (26%)]\tLoss: 0.000062\tAccuracy: 100.000000\tTime 0.865 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[7680/27064 (28%)]\tLoss: 0.000078\tAccuracy: 100.000000\tTime 0.864 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[8320/27064 (31%)]\tLoss: 0.002231\tAccuracy: 100.000000\tTime 0.868 (0.863)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[8960/27064 (33%)]\tLoss: 0.004595\tAccuracy: 100.000000\tTime 0.868 (0.863)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[9600/27064 (35%)]\tLoss: 0.008757\tAccuracy: 100.000000\tTime 0.867 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[10240/27064 (38%)]\tLoss: 0.009334\tAccuracy: 100.000000\tTime 0.871 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[10880/27064 (40%)]\tLoss: 0.006650\tAccuracy: 100.000000\tTime 0.872 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[11520/27064 (43%)]\tLoss: 0.005796\tAccuracy: 100.000000\tTime 0.868 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[12160/27064 (45%)]\tLoss: 0.000127\tAccuracy: 100.000000\tTime 0.866 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[12800/27064 (47%)]\tLoss: 0.001245\tAccuracy: 100.000000\tTime 0.869 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[13440/27064 (50%)]\tLoss: 0.002716\tAccuracy: 100.000000\tTime 0.869 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[14080/27064 (52%)]\tLoss: 0.000299\tAccuracy: 100.000000\tTime 0.865 (0.864)\tData 0.013 (0.007)\n",
      "Train Epoch: 9\t[14720/27064 (54%)]\tLoss: 0.003198\tAccuracy: 100.000000\tTime 0.865 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[15360/27064 (57%)]\tLoss: 0.000289\tAccuracy: 100.000000\tTime 0.867 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[16000/27064 (59%)]\tLoss: 0.001067\tAccuracy: 100.000000\tTime 0.866 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[16640/27064 (61%)]\tLoss: 0.000475\tAccuracy: 100.000000\tTime 0.866 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[17280/27064 (64%)]\tLoss: 0.000171\tAccuracy: 100.000000\tTime 0.867 (0.864)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[17920/27064 (66%)]\tLoss: 0.002928\tAccuracy: 100.000000\tTime 0.870 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[18560/27064 (69%)]\tLoss: 0.000184\tAccuracy: 100.000000\tTime 0.866 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[19200/27064 (71%)]\tLoss: 0.000574\tAccuracy: 100.000000\tTime 0.870 (0.864)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[19840/27064 (73%)]\tLoss: 0.001720\tAccuracy: 100.000000\tTime 0.869 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[20480/27064 (76%)]\tLoss: 0.015761\tAccuracy: 98.437500\tTime 0.867 (0.864)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[21120/27064 (78%)]\tLoss: 0.000382\tAccuracy: 100.000000\tTime 0.871 (0.864)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[21760/27064 (80%)]\tLoss: 0.011441\tAccuracy: 100.000000\tTime 0.871 (0.865)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[22400/27064 (83%)]\tLoss: 0.001591\tAccuracy: 100.000000\tTime 0.869 (0.865)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[23040/27064 (85%)]\tLoss: 0.006917\tAccuracy: 100.000000\tTime 0.872 (0.865)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[23680/27064 (87%)]\tLoss: 0.014240\tAccuracy: 98.437500\tTime 0.870 (0.865)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[24320/27064 (90%)]\tLoss: 0.005673\tAccuracy: 100.000000\tTime 0.870 (0.865)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[24960/27064 (92%)]\tLoss: 0.001802\tAccuracy: 100.000000\tTime 0.872 (0.865)\tData 0.012 (0.007)\n",
      "Train Epoch: 9\t[25600/27064 (95%)]\tLoss: 0.007383\tAccuracy: 100.000000\tTime 0.872 (0.865)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[26240/27064 (97%)]\tLoss: 0.000873\tAccuracy: 100.000000\tTime 0.873 (0.865)\tData 0.011 (0.007)\n",
      "Train Epoch: 9\t[26880/27064 (99%)]\tLoss: 0.000454\tAccuracy: 100.000000\tTime 0.869 (0.865)\tData 0.011 (0.007)\n",
      "\n",
      "Val set: Average loss: 0.006916, Accuracy: 99.981618 \n",
      "\n",
      "Train Epoch: 10\t[0/27064 (0%)]\tLoss: 0.000378\tAccuracy: 100.000000\tTime 0.866 (0.866)\tData 0.005 (0.005)\n",
      "Train Epoch: 10\t[640/27064 (2%)]\tLoss: 0.000393\tAccuracy: 100.000000\tTime 0.871 (0.867)\tData 0.011 (0.007)\n",
      "Train Epoch: 10\t[1280/27064 (5%)]\tLoss: 0.001521\tAccuracy: 100.000000\tTime 0.868 (0.867)\tData 0.011 (0.007)\n",
      "Train Epoch: 10\t[1920/27064 (7%)]\tLoss: 0.000880\tAccuracy: 100.000000\tTime 0.866 (0.867)\tData 0.003 (0.007)\n",
      "Train Epoch: 10\t[2560/27064 (9%)]\tLoss: 0.000387\tAccuracy: 100.000000\tTime 0.865 (0.867)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[3200/27064 (12%)]\tLoss: 0.001174\tAccuracy: 100.000000\tTime 0.866 (0.867)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[3840/27064 (14%)]\tLoss: 0.001684\tAccuracy: 100.000000\tTime 0.863 (0.867)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[4480/27064 (17%)]\tLoss: 0.001493\tAccuracy: 100.000000\tTime 0.865 (0.867)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[5120/27064 (19%)]\tLoss: 0.000899\tAccuracy: 100.000000\tTime 0.867 (0.868)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[5760/27064 (21%)]\tLoss: 0.001052\tAccuracy: 100.000000\tTime 0.867 (0.868)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[6400/27064 (24%)]\tLoss: 0.001752\tAccuracy: 100.000000\tTime 0.866 (0.868)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[7040/27064 (26%)]\tLoss: 0.001232\tAccuracy: 100.000000\tTime 0.866 (0.868)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[7680/27064 (28%)]\tLoss: 0.001685\tAccuracy: 100.000000\tTime 0.866 (0.868)\tData 0.002 (0.007)\n",
      "Train Epoch: 10\t[8320/27064 (31%)]\tLoss: 0.018399\tAccuracy: 100.000000\tTime 0.871 (0.868)\tData 0.003 (0.007)\n",
      "Train Epoch: 10\t[8960/27064 (33%)]\tLoss: 0.008078\tAccuracy: 100.000000\tTime 0.868 (0.869)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[9600/27064 (35%)]\tLoss: 0.005223\tAccuracy: 100.000000\tTime 0.867 (0.869)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[10240/27064 (38%)]\tLoss: 0.007419\tAccuracy: 100.000000\tTime 0.867 (0.869)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[10880/27064 (40%)]\tLoss: 0.004688\tAccuracy: 100.000000\tTime 0.871 (0.869)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[11520/27064 (43%)]\tLoss: 0.003210\tAccuracy: 100.000000\tTime 0.873 (0.869)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[12160/27064 (45%)]\tLoss: 0.000927\tAccuracy: 100.000000\tTime 0.869 (0.870)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[12800/27064 (47%)]\tLoss: 0.005502\tAccuracy: 100.000000\tTime 0.870 (0.870)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[13440/27064 (50%)]\tLoss: 0.000972\tAccuracy: 100.000000\tTime 0.871 (0.870)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[14080/27064 (52%)]\tLoss: 0.001192\tAccuracy: 100.000000\tTime 0.868 (0.870)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[14720/27064 (54%)]\tLoss: 0.001911\tAccuracy: 100.000000\tTime 0.867 (0.870)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[15360/27064 (57%)]\tLoss: 0.001468\tAccuracy: 100.000000\tTime 0.872 (0.870)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[16000/27064 (59%)]\tLoss: 0.000821\tAccuracy: 100.000000\tTime 0.868 (0.870)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[16640/27064 (61%)]\tLoss: 0.002904\tAccuracy: 100.000000\tTime 0.869 (0.870)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[17280/27064 (64%)]\tLoss: 0.093646\tAccuracy: 96.875000\tTime 0.871 (0.870)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[17920/27064 (66%)]\tLoss: 0.003243\tAccuracy: 100.000000\tTime 0.870 (0.871)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[18560/27064 (69%)]\tLoss: 0.010512\tAccuracy: 100.000000\tTime 0.870 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[19200/27064 (71%)]\tLoss: 0.014804\tAccuracy: 98.437500\tTime 0.868 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[19840/27064 (73%)]\tLoss: 0.001328\tAccuracy: 100.000000\tTime 0.867 (0.871)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[20480/27064 (76%)]\tLoss: 0.011075\tAccuracy: 98.437500\tTime 0.872 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[21120/27064 (78%)]\tLoss: 0.002417\tAccuracy: 100.000000\tTime 0.870 (0.871)\tData 0.003 (0.008)\n",
      "Train Epoch: 10\t[21760/27064 (80%)]\tLoss: 0.002623\tAccuracy: 100.000000\tTime 0.872 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[22400/27064 (83%)]\tLoss: 0.002941\tAccuracy: 100.000000\tTime 0.870 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[23040/27064 (85%)]\tLoss: 0.001984\tAccuracy: 100.000000\tTime 0.869 (0.871)\tData 0.005 (0.008)\n",
      "Train Epoch: 10\t[23680/27064 (87%)]\tLoss: 0.002155\tAccuracy: 100.000000\tTime 0.867 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[24320/27064 (90%)]\tLoss: 0.003393\tAccuracy: 100.000000\tTime 0.869 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[24960/27064 (92%)]\tLoss: 0.003644\tAccuracy: 100.000000\tTime 0.870 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[25600/27064 (95%)]\tLoss: 0.001694\tAccuracy: 100.000000\tTime 0.870 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[26240/27064 (97%)]\tLoss: 0.001494\tAccuracy: 100.000000\tTime 0.869 (0.871)\tData 0.002 (0.008)\n",
      "Train Epoch: 10\t[26880/27064 (99%)]\tLoss: 0.001414\tAccuracy: 100.000000\tTime 0.872 (0.871)\tData 0.003 (0.008)\n",
      "\n",
      "Val set: Average loss: 0.002069, Accuracy: 99.963235 \n",
      "\n",
      "\n",
      "Val set: Average loss: 0.002069, Accuracy: 99.963235 \n",
      "\n",
      "\n",
      "\n",
      "Best validation accuracy: 100.000000\n",
      "\n",
      " Total time taken in seconds:  3894.5012032985687\n"
     ]
    }
   ],
   "source": [
    "# Trainging Loop\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "best_acc = test(valid_loader, model, criterion, device)[1]\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    acc = train(train_loader, model, criterion, optimizer, epoch, device)\n",
    "    acc /= len(train_loader)\n",
    "\n",
    "    current_acc = test(valid_loader, model, criterion, device)[1]\n",
    "    \n",
    "    if current_acc > best_acc:\n",
    "        best_acc = current_acc\n",
    "        print(\"-------------------- HIGHEST ACCURACY ---------------------------\")\n",
    "        torch.save(model.state_dict(), './model.pth')\n",
    "\n",
    "training_stop_time = time.time()\n",
    "\n",
    "best_acc = max(best_acc, test(valid_loader, model, criterion, device)[0])\n",
    "print('\\n\\nBest validation accuracy: {:.6f}'.format(best_acc))\n",
    "\n",
    "print('\\n Total time taken in seconds: ', training_stop_time - training_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-PusJd6f_FQ"
   },
   "source": [
    "#### Testing time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BoOtctOAApZ",
    "outputId": "84b5dbd0-90bc-4528-88a0-9c3d3269c004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.024339, Accuracy: 99.995381 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CapsNet(A=A, B=B, C=C, D=D, E=num_class, iters=em_iters).to(device)\n",
    "model.load_state_dict(torch.load('./model.pth'))\n",
    "test(test_loader, model, criterion, device, test=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B93ieiCMZ5eB"
   },
   "source": [
    "## **Inference and Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-xUh6iustlT"
   },
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IG8C_OQZ8H6"
   },
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krZ2Z-9bZ-mA",
    "outputId": "e5d4245e-4e85-47a9-88f0-5bfff02245fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.024339, Accuracy: 99.995381 \n",
      "\n",
      "------------------------ CONFUSION MATRIX -------------------------\n",
      "[[ 803    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0 1490    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0  791    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0  558    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    1 1068    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0 1584    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0 1432    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0 4509    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0 2482    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0 1311    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  427    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  771    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  366    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  428\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  2907    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  722]]\n",
      "\n",
      "\n",
      "---------------------- CLASSIFICATION REPORT ----------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       803\n",
      "           1       1.00      1.00      1.00      1490\n",
      "           2       1.00      1.00      1.00       791\n",
      "           3       1.00      1.00      1.00       558\n",
      "           4       1.00      1.00      1.00      1071\n",
      "           5       1.00      1.00      1.00      1584\n",
      "           6       1.00      1.00      1.00      1432\n",
      "           7       1.00      1.00      1.00      4509\n",
      "           8       1.00      1.00      1.00      2482\n",
      "           9       1.00      1.00      1.00      1311\n",
      "          10       1.00      0.99      1.00       427\n",
      "          11       1.00      1.00      1.00       771\n",
      "          12       1.00      1.00      1.00       366\n",
      "          13       1.00      1.00      1.00       428\n",
      "          14       1.00      1.00      1.00      2907\n",
      "          15       1.00      1.00      1.00       722\n",
      "\n",
      "    accuracy                           1.00     21652\n",
      "   macro avg       1.00      1.00      1.00     21652\n",
      "weighted avg       1.00      1.00      1.00     21652\n",
      "\n",
      "\n",
      "\n",
      "------------------------ OVERALL ACCURACY -------------------------\n",
      "0.999953814890000\n",
      "\n",
      "\n",
      "\n",
      "------------------------ AVERAGE ACCURACY -------------------------\n",
      "0.9999701622408173\n",
      "\n",
      "\n",
      "--------------------------- KAPPA SCORE ---------------------------\n",
      "0.9999800105316705\n",
      "\n",
      "\n",
      "-------------------------- TEST ACCURACY --------------------------\n",
      "\n",
      "Test set: Average loss: 0.024339, Accuracy: 99.995381 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def report(model=model, test_loader=test_loader, criterion=criterion, device=device):\n",
    "\n",
    "    # Getting prediction vectors from test loader\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "    test_len = len(test_loader)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(device))\n",
    "            y_pred.extend(output.argmax(dim=1).float().tolist())\n",
    "            y_test.extend(target.tolist())\n",
    "\n",
    "    target_labels = ['0', '1', '2', '3', '4', '5', '6', '7', \n",
    "            '8', '9', '10', '11', '12', '13', '14', '15']\n",
    "\n",
    "    classificationReport = classification_report(y_test, y_pred, target_names=target_labels)\n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    oa = accuracy_score(y_test, y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusionMatrix)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    test_loss, acc = test(test_loader, model, criterion, device, test=True)\n",
    "\n",
    "    print(\"------------------------ CONFUSION MATRIX -------------------------\")\n",
    "    print(confusionMatrix)\n",
    "\n",
    "    print(\"\\n\\n---------------------- CLASSIFICATION REPORT ----------------------\")\n",
    "    print(classificationReport)\n",
    "\n",
    "    print('\\n\\n------------------------ OVERALL ACCURACY -------------------------')\n",
    "    print(oa)\n",
    "\n",
    "    print('\\n\\n-------------------------- EACH ACCURACY --------------------------')\n",
    "    print(each_acc)\n",
    "\n",
    "    print('\\n\\n------------------------ AVERAGE ACCURACY -------------------------')\n",
    "    print(aa)\n",
    "\n",
    "    print('\\n\\n--------------------------- KAPPA SCORE ---------------------------')\n",
    "    print(kappa)\n",
    "\n",
    "    print('\\n\\n-------------------------- TEST ACCURACY --------------------------')\n",
    "    print('\\nTest set: Average loss: {:.6f}, Accuracy: {:.6f} \\n'.format(\n",
    "        test_loss, acc))\n",
    "\n",
    "report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfyI8o-raJm3"
   },
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAsXUh8TaaRR"
   },
   "outputs": [],
   "source": [
    "X,y = loadData()\n",
    "X = applyPCA(X)\n",
    "X = padWithZeros(X, windowSize//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emvkETrFaslj"
   },
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index + windowSize)\n",
    "    width_slice = slice(width_index, width_index + windowSize)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aB1sYuXwaupH"
   },
   "outputs": [],
   "source": [
    "height,width = y.shape[0],y.shape[1]\n",
    "outputs = np.zeros((height,width))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for i in range(height):\n",
    "      for j in range(width):\n",
    "          target = int(y[i,j])\n",
    "          if target == 0 :\n",
    "              continue\n",
    "          else :\n",
    "              image_patch=Patch(X,i,j)\n",
    "              X_test_image = image_patch.transpose(2,0,1)\n",
    "              X_test_image = X_test_image.reshape(1,X_test_image.shape[0],X_test_image.shape[1], X_test_image.shape[2])\n",
    "              X_test_image = torch.Tensor(X_test_image).to(device)\n",
    "              pred = model(X_test_image)\n",
    "              pred = pred.cpu().numpy()\n",
    "              pred = np.argmax(pred, axis=-1)\n",
    "              outputs[i][j] = pred[0]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hk9UvESa4Be"
   },
   "source": [
    "##### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "oaSqDBy_a5Ep",
    "outputId": "d49fc93a-c80f-424d-c191-7dcd7c025033"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c_v4cuGa7o3"
   },
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "jKAdGZCMa80E",
    "outputId": "923124a1-9de6-4d9e-9c2f-1b02df774fb5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAAGfCAYAAAD1ZvZbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2df6x0W1nfP08B8QfGV7i3eHK5AgoJl7RGD2+Y3XhjWq0KzEnBplX6Q4lhz03vwRRjm3qNOdX0/UebVFsT3re9syGAUYnxRyFnsEjRxph0T7l3iggCcqEo9+YARQW1VIH69I+11syePXvP7L1n/z7rk7znPWfOzN77zKzvfn6sZz1LVBWPx5PPX+v6AjyevuNF4vEcwIvE4zmAF4nHcwAvEo/nAF4kHs8BGhGJiLxERD4kIo+JyENNnMPjaQupe55ERJ4E/D7w7cDjwLuBf6Sqv1friTyelmjCkrwYeExVP6qqnwfeAry8gfN4PK3w5AaOeQ/w8cTPjwOTfS8QET/tD7yooeM+WtPxHz38lEGjqpL1eBMiKYSIPAA80NX5S5En4cy3tPoppIESIRUQFRB4VM2Z4lm5C59Eav/UA68zfwSK1PnWdE4TInkCuDfx87PsY1uo6sPAw9BvS6KAiJJ1kxHz21rOI+5Lze+EKKjYYVvi+MHcPFFF8oe8Pfb6XEAcChLV9770gSYC9ydjAvdvw4jj3cA/VtX373lNr0SiaoSx/qA1e2y559gbdGm2zuHOI0rd74Y1JJhrVZZh/gAO5rplfbIPuP6SaZXMMYZnTVpzt1T1iyLyA8A7gCcBb9gnkD6hKDOWnJ2tmN4+4/Lc3nzFDq/Ue6gqyPouraV1onYgro/a0KgSBV2fKP8kk0ghYmN1djB/43Ime48Tz4QajWznNBKTqOrbgbc3cexGUGAWc3Z6Bovp+uElIRAd/KzNeJC1T14Y0Yw7tjRiTcSYKVTMnd5ZgDJulagTSMHzjUQltbtblS6iI3fLeQ13zqYsmO78fsqC88vFxuvKucrNDbq8NUEFSY0l1bUTVytGjzYwUfa7VSnXr2ywH8xtAD8gneS5W9dWJHEIUQhXt27vfd7iYgVBZH7IiU2AxEAr/6ekM0eNZrrAZp9y7vT2b1zOjj/f0GKTPJFcu9otRSGMuXU6PSgQgNu3rnADX8UF27uI8frNnbnsNalsaetA6FAZ0WSokIqvcHZQaxEIGOvThEVsm+tjSaz7cHZ7O+4owsXJ+dqY7Mt06dovo1xsQsbAbSDTZdyfXQuimPOUdamKMCRrcr3dLetbTa9W1V4/XbA4XwDuTpwzb7IegBViE3bjAzd4j2V/SleJ96SE62AyZxCxyfV0t+KQ29Mp09VVdYG4QxECh72g9Ziu4nbtPCJVDrM+vVq/LT+la34/iZq9R5mbSqOnaJRRWhJVkGXIdHVV2rXKo2ymSyu4XJBhTSpkuvLcqsQTbCXB9gNNuFuOSbROlPeWa2JJlJCYsztTprdOaxMIYFLEy3D9877J6GNmCHbkUPJAm7RrTubK5b3FXWmFk1RgGUrtcz9tMQqRKBDGcHt6xtV0Vas4kkxXxTJd7veVfaWEVIpkupxrpZI9L+EyV6aGyxzbZbo2tHGPH6ZKhu9uxfW6VYe4vDzfDMQDNV3pAsDCqGyLY0+ma11xmzchCHZmP+dciRcfquuqg6DHxY+jc7fUulZtCgRgKRuXa581MYOTatZEdDueSc/IC25Wxgg2J2tlnrU/Q5Z2ulyZSmN0f08uzaBE4tzp29MpZ7ebda3yuHX7av1B58YluplEq2okk4PXnW0rY5UnDrWuVcHzbOuxejatDD1wXkoxGHdLMQWHt6anLVzRfhYnpxAF659z30JJ+P5V3a7koN3nqRwx+bip6XIHup6ZrmG7W3HILKYXAgG4fXVr616d92ELerz7nRz0eeXr1sQelz3yma48eisSl5Fxk4FF6qzaYsGUGcv1z3mxiapsYpOy2LUqey2Hleqx9VHpTJe2Mj0+HJX01N1Sbk/PMsvXO2e6WMdBZTJdhScXbWZrTwU7x1uNHK55pmsw7lZMCOGyukCmi3ovKE0iUTDbGJP98ybOIORFxTYiX4/RfVUkDdJNpqv7m/Qh+mFJboryOjvfAa1nrCozXbB4cJEY0fsLHzOtiR4oIcnAHacZv36j0DasienE0g9r0usq4Bs3nq33319zN9SEW9QkJxfnyURX8UzXAbcqi6SU6qoQ3jlHMtNl7/RNZroAgjm98LoG425VIsvFaskaXa2mpTNdpd0ql70qcJ56ODARVPfZep7qGodIunTPFsUzXcC6+LDI+FOMZdL19xuZaEMTf2trZ0/URqZrGfZ7/eLwRNJ0YF6Bq+kKN6qyhpRpO1SC9SjV7SnxZIFizrnqIJkSFmh8vYk5Z39lMjyR9DSo33ZnbT+u9TxHQb/KimO3JCX1lMR5miojkYQT2UqmC+hrpmt4IukpZ3dS4lVbgFjgtWm36lBEvnXTbbTYaiOTpmu64ll/Xa7xiqQLtyw5evMXBZK8Y649q3Tl76FTudNIOzoRlcatyTKUXhqT8YqkbbdsMSVc5o/W9Uz5ei4lEVvYlHBhpJ1M11a5yjXOdI1XJB1wtZoSh1m/2YgjOxVffgS2kekCSC7zbSvT1bda+mGIpIcZrUwWU6IwVSzo/s9otp18Yul1J21mulz6mnYyXUCv3K5hiKSnGa0srm7d3h78+56c6ESvlA8uxprp6lsQ3x+RDMVaFCCd6cqbJVHdrKuoag3GmOmyZ+mNNemPSAZkLQqh24H1nmUhm+8rrolPZroapcVMV5+sSX9EMiYyMl37WxDVl+lqKjjpItOVdPO6xIukIdKZruLjqueZrhZruuKZ9KJcxYukKTLcx0370dTjQ8p0ue8pnuk62jXrWCdeJA2yupq2l+lK1Y71KdN1zHqUPsQmXiQNYpYgb3/EjWW6RItUxdSEru3Wdch0eZE0zPTO2dbPbWW6mpRJstd2a5muDstVvEhaICTe+rlopqs06UxXk/Zke2+5RgnmTa3nL4YXSdPYUpUqWdq9HVZy2Mp0NVghLK5ymeYyXcFcmczBrMfpbhG8F0kLTK9WxKnNOgtluqqMi5YyXQAkjIkZzPWxboXa+B9xmCd3e/rrw63TKeim/dDhTJesB3lZT0O32hRJ7RuUps6GW4mJHpfJcrGN2Yi0aJeM5vGWpC0W00xrkkUy01UpgBfdcrvaqVY5LtOVdKt6oo013pK0yK3TKbAp5HSDIesmv7ED9mezhW7xk4km9l9szppseolh97Av3qdrbTmQ4iFHS8mCJN6StEyVTFfVQZHI1NoB3BAVMl1mf3eM5SjwOlXzpYskl7ckbeIyXYmOhYfGR9KiHGNNnEaatCbGM5Tk/qs7BHO19WWH3SpzTLPP/HIGMWI6nLVsTbxIWmZ6tWKR+pRdpitr9aL1lqpF8OyKrDG3i02yQeewTMRfSbeKgq6V25o7y3UzG6S2pxIvki5YbkfwRTNd1cfFJp3arLuym+lybpUUGNZqvwjKcibEOa9wqwnakokXSQdMb52ySLkMezNdmOdWdbnUjqg2physTEwZiVLKrRIrrDxxOIx1ac/n8oF7R8Sy7bgXrekqvSgL2N6mocEK4WSmwFqugwJREDVxR5k5lu1zNYsXSUckd/EtxnGzHm1nuvadwSaqQDU37jjE2pq0IJTxiqTvjSUW0x1rsj8dnJJJFWuy7p/VTE2XixNyN/SyX0XVZKtm5axHmrbWmoxDJB3uT3IMq+lV5hqQvJouOc6YbPXPQutzu3TtK9rsVea5q7lVh2hDJuMQyQAEkcWCKbIzqbBnACVWLx6X6aqvqHaTZcoP0O3MSGM7ZjU9xTg8kfTdjSrJ9Nbprl+dc4vfsiZVqLGmy1kPyUs5tLRK0jSLaDY0GZ5IBmo19hEut3/eF5skB3ilwZfIdFXprLKJZ7KvwAXl2ysJm03Vuq4qTQlleCIZIVerjIYRe0dvokS44hLf9Ux8wdebZS6CqGRODK4zViQSBFujtgWhNCST8YpkSG5Z1UxX1XFXIdNlaxFzzmkyVm5C0J5iK4ZSaaHZdkOHH69IBuaWHZXpqmJNCmS6nPXQPHUo6x26stja7tH+a7ppRBO97MYrkoGxYJrhLhzOdB0VfLsBnCOQvFlz466pLTTcXzCpsr2Bd5PzmE25XMMQyZBcpypMF1ycnGeP+CKZrioDzzVxSB0iOeeRFZa7+Y6iu9eJbs9lNG1NNnVd9TGMAseBuU6FsMJfnJ5AcMkiL1sktgw9QyzJMnj3cymS601c9S4JNyx1NleIWJZti1f/IM46YZ1Vwv2xJGO0Fjl/0+LklIvzExbnCwgi1h/nJkW0ps1MV9p6uNJ1dQI5Ymy3numqMTjpj0jGaC0y/qbFySlEEwKixKN2GC5D4y6kPt/GMl2aOxXIRj7FXas8Osl0mTPVchTRHrS2v3Hj2Xr//Q91fRnNYS3K5fllojkD61t1PBOCcJMC1mCeMxNBptvl5va2o4wcklmtvEJEreZWHSbpA5m0WFOlKmCEWGYFo2bv+tojSzJSTi7OuVgtWJwvcL2knBsTz4DlbEsgYHegrZrp2uNyOatxsOFbQ+O2zVl4cNbveLF7S9IQi5NTmE92Vuat79KpJbw7TOa7udl9cxL2S6Y1Sa6V30MywG7MmiQvJGFJm2LdCbLAcytbEhF5g4h8SkTel3js6SLyThH5sP3/q+3jIiI/IyKPich7ReS06B8zGqYLLhcPolFAutGaYtZRHBQI5jlZdY+5sYl9fG0kbCAvWqRVqEvtJg5HpTzAQbZE3LwxYRkeWRRKMXfrjcBLUo89BLxLVZ8PvMv+DPBS4Pn23wPAnUpXNcRM13TBxWJl4o7kncvdLUPzgaVdq32kq+j3uVOqCRfNBeSHxOFmzO26eSVhgxpSSXJf+M2JmuY4lRycJ1HV3xKR56Qefjnwt+33bwL+G/DD9vE3q/HhYhG5ISInqnpV6qoGlum6WKyYLC6tNEzWyrnDyxkE8YyA4uLYJjWvvmfeJPmcg0d0rtuW+XDtKGR9nGNTv9mXl5jIEJigNg6rn0mkMD/u2FUnE5+ZGPifAJ5pv78H+HjieY/bx3ZEIiIPYKwNX/ZlT694GR0yXTBdwPnlgksB2UrpmllpljMqawMIwhCNsse869Ml65nzgz6Ved7a2GSPfHXuGc1O+yV7ZwnAvL7YpO7G20fPuKuqSumdMEFVHwYeBhO4H3sdbTJlwYPWrdrJaoq9K87KuVZ5LEOBKF2lZYbvunNKgXGwmS2XAqYheb5mpLJdUlPPOVx3SNKfy5FUFcknnRslIifAp+zjTwD3Jp73LPvYaFhcrLicLJCdqkBzJ5R4xlHmI0UQhlttUTdnK9iwLuEv7bhXWWT06TLnql8o250YTSO7qtbEuVVN7PVTVSRvA14F/IT9/62Jx39ARN4CTIDPlo5HesiUBauLBfMAZJEal26+g3osRyY201U23K08rLc60m9i+Gb2OHHWjcoXvJ40bCgHcFAkIvILmCD9LhF5HPgxjDh+UUReDfwB8N326W8HXgY8BnwO+P4Grrk9pgtOzi84V1Ohux11bGaMGxNHgmVIbnySuCJgM78hbLJWZdn1hup3u0zyIHn3rzbKm2576icTs5guWJyeoJMoe60Fat2qdsksV1mP5u2Ml4jzz6mcokpmutbpgUaGy2aEa8VMV9bca1l8WUoRpgumLGz5epZANvMdXbAMZfdmLuwIBFivNznmSrdEd8RxDp4noTyh2noToblGEMNYT9ICi5NTOF2xOI+Sm1Gts0JxKAThMfMdxxOEISpZ1iRngtH+X7mb/M6qrv5mutbV0z0K3MdBXnVuAjff0aU4kkg8Q4PtS923MMulfasO71YzXYnt66pkuqQhlVxfkbi4I4h2MiPO/16GQlCkzqplRHXLARc4WEKiVafPW8p0be0od4TBSuzmUhvXUiQXixWcLFhkLit3QXm98x11Es+EIHXTzLMmblb+qEyXJCppG8p0mUMn01TlB/q6SV3Nma7rE7jboPzy8pwJkVk1m0TNXSjuKCgvg4lNtgdpkTlFY00qplmToqh+mIMkCyyrrF5somPK+C3JdMFidYGeP4ggnGdkUEWbmS1vkmUoGTPxOQF8Yj1J1eHTVk1Xcu9FgWo1XTXPm4x6nuRisYIww2pYuprvqIu8eZPcT1TcxFu1zzw5b7L/RMfh9lg0P1QrVakybzLueZL0+pPpgpOLHLcKcAsphiwQsJmu1GP7FmYJdu/0ir5SsiN9lWbb5U7mvil/kmCutbpc43C37PoTV2MVTdgpI3GJnXWd1b7NxgdE2UxXwg5UORmuJWqT+khnuoKC1sTt9Gs++PqucBwiwVbnBpfIIitflZjvGIc21lTJdKlI9TxuqqHd9qal9VE20zWJFCJ23c86rmXQMcl0wcnpgig9ShKoqzfq4XxHXeS1IMqcXFzvC6/rZbvlT7gJ4tWa6CaEkoxNsmq6NuUr9Vi3vJhksJZkyoLT8xMCIPvtMencJbK7WHxk5C/M2mWT6Tp6SIGt4G3yNuv+qmSmK8utatb9G5olmS64WC0IdgaFxfqzyxmtlLD3hTjKm/vJ4chM1/aKyPYyXck9Gms/16AtScHm0i5dKGE4lOmOWkmXZByq6RpCbAKszUm6h1lb9F4ki5NT4vNVonfubk537a+2tACqjwRhSIxsLcw6lOlyz6k8wZg8TwOk09Vd1UL02t1yzaXz3x7b3nPg8x11kl4o5kr984J4k9KtPgac61P3oqzCa/hrZDjuVrp8PWsyUM2XtWvlWbOcsbWuosgYO8qa6GY3LLWCOybMcVfUldXIolcz7icX5yxOT7aaSyex2shtNO2xxY87j+Znusw3cmTFol1Tf8QhTGiUvbNv1/TC3Xr2jRv6h5/5zN7ArHCjaU+lTFfVdfDm2MdlurpwrTKvo8+1W3/4vM+Sbi69wdRZFW407QFctJb4+UBN11EDNOFiFa3pcsZLpUhD727phSXZ1wFSFWTkk4FNEEcRk3QLop5Yk/XOvtXO1Bi9tiR7EfOBe8oRhOHOQD1kTY4atLKpvN1rTXoqkH30XiSCqdHxQinPOtNlKZrpqoq7Ebv5ma28AILzq4YkEBiASIAa6oyuJ5UyXUeznelSm68a8kc4DJFgVpp5yrOckd71es/ULMelg22TvM3phi0Ox2BEIvjYpApBGO6s0iuyrVxlEpmuEegDGJBIEG9NqhLPZMuaHKrpKlLztY/u86X1MhyRgM90VcRZk+TgzbMmbiFWhX2ZEgcu+ZLEvz4yKJEIZpmmF0oFljO2o4UCFLUm6zhmU8dVGMU29tbNPo49Y1AigSEmEPvDbuO9PZmuggJxk+VlxOFq8NaTl+sgpp9CGZxIwMcmx1Am05UbmyQsR2Ka/fC57RdJi2PrghpcvFWRQYrEZ7qqcXSmy4lDylkO89oD4th9em/o33qSIghMFFh2fSEDZDkj2aqrSKZrq5tACWWsS8HK7iZk95Ovvz98NQZpSQCf6TqCnV2hDlqTI92qqtfZE3MyWJGYTJcXSiVSma40YlPAbk/0Jt2qvfQkih+sSGCTEvaUJy/T5dycMuLQ5Jc6xNEzBi0SMEs+vTWpxs5SonJeVW1u1V56YE16v+iqCH5hVkWO2dd53U+opfHTdJduhrzoqgA+JVwRm+kqStduVVe381GIBPELs8oSR5G1JMVf06hbVeDkXXle4xAJ+IVZJQnmZrKk1LsmHNl66Eg6mo0fj0jwma5yVF1YRedCaftTHpVIfKbrMHEUoUE5N2uHjoXStjUZZllKHr5cZS+mzVBNxR5OKF3FKFu1Ms0yKksCPtO1j9oE4ujKorjMWkv6HJ1IfKYrm+wt4+o6eEeuV0vxyfhEAj7TlSKOouY8k47f6ja8vXGKBJ/pcpjm2Q078F0G8i24XaMVic90tSQQhxNKR2JpUiejFQlyva1JqwJxdOV6NTzJOFKRqNlk85puE9eJQBxdZrwaEsq4RKKAmv3br6tANnQ5K05yA5J23bAGhDL8UnkFFbv7Ltdr7/YsMvcl6QvJT7kp/8h2s6/y9+eVyg9SJJuSbdMQ+roLwxFHEcGcnipkg3EEGxx3FVUyGpG4Pdu9MLZpwoJs3fhrPO764E1G21XarQ5VJO69VDZbJnqBZFCzQtILD93wqesUfbQmgxSJ33G3IJP53p2Li1JkRe6h+LvM+vhGRQKlhTKw5buK33G3IHad+jECUXbb8ubhnpP1zx2rCOumeE1mvWqq7eqvJVFvQQ5yTCMHS939HEq7ZS3EJkUNysAsCYAvK9mLdbGq4CxHE/0cSlexNz35WMPa+P6KpOdpzC6Jo6hSn9wybtWxlBYKDbpeR5at9EMkL3pR5sOB32IhkypeVlviSFL6Dt6kVTnCnPRCJC/4g0ez/wAxi4U8hjiK0ElUWCBpt6oLeieUCvRCJB+86678N7LLzhw9Io6iUhakC8uRR6+EUuH9OCgSEblXRH5TRH5PRN4vIq+1jz9dRN4pIh+2/3+1fVxE5GdE5DERea+InBa5EFmGecbEB/CUc7G67CGXh6zNWtEX0IxQKrhdRSzJF4F/oaovBALgNSLyQuAh4F2q+nzgXfZngJcCz7f/HgDuFL+cjKv3a9bN3z5ggWzRk8xXmbfooEhU9UpVV/b7PwM+ANwDvBx4k33am4BX2O9fDrxZDTFwQ0ROilzMMsyZg73Ga9bd2pBCeX56LhBLpRRxnWIpmRYuFZOIyHOAb8J0tnqmql7ZX30CeKb9/h7g44mXPW4fSx/rARF5REQe4TN/AbiarOxLv46rDMssnhqKQBxlhaJ1W5USaeHCIhGRpwG/DPygqv5p8ndqpu3LlburPqyqN1X1Jje+dP34MpRsr+uaBfBjFoijjFDWGql5HBQ5fyGRiMhTMAL5OVX9FfvwJ50bZf//lH38CeDexMufZR8rRBBmB/Aq1yuAH7tAHH0QyiGKZLcEeD3wAVX9qcSv3ga8yn7/KuCtice/z2a5AuCzCbesEFmZLuEa7d8+mVMkChm6QBytC0XFvL8Fa7qKWJJvBr4X+FYReY/99zLgJ4BvF5EPA3/X/gzwduCjwGPAHDgv/UcAeZmusSsljqJayt6HhksRFxFLJaHY4L+MOBwHG2ar6m+Tf8xvy3i+Aq8pcQ2ZLENBU5lP974sw2iUC6/KrC4cixVJI1psGYgbC+tY9cAiGHfMKjefXsy4Z5GX6RrtPXYyv/YCcRR1vw7WRVa0HGl6KxLIz3QFI0sHl3Gxxi4QR+k4xanlCLcqj16LJC/TNbZ6rmA+rsnCuqgS0Kv1qeocIb0WCWRnunREAbzZder6ZLLKUjagb+L22XuRAEhqibEzr0OeN3G73xZxsq6rQNJ09RYMQiTxbLemS2zh41Bxu98ewgvEULbRRJ0MQiS5NV0DnoUvuj59XNFXderu+1WGQYgE8jJdwxtC69WFJV4zsjxFKVww3lS8UYTBiCQv0zWk1b1lVxc6OihX6pw+iMMxGJFA/urFIaDB3KwL6foTHwB9EYdjcPu4i6YCXgFl3qv9SNJxkplJPz526nLb9KZJxhx9EYdjcCKJZ8KE3ZquOGq/nsvUWmWN2vp3uzVp73HSZVBehH60Ob3vbuWNrzj8REvmnuQNtkXdLIDKor2Pdmzp4Kqb7TRFXpvTwVkSsJmu1GY1KsIyrLYtQ9I9Cuaak57t/uPcVL52fSXH0XfLkWaQIjGZrmjX5apysMmcSbLhW9RunbEb70MZMMfSN+tRhEFlt5JkZbpKl3O5fT06+NRKNwUYOE0UHrbFYEUC2TVdh2bg4ygyE3pBxLH7elTlGHEMbc5kyOJwDNLdcuxkugQmiml4lPX8Lvc3p17L0ffYZGhxxz4GbUkya7py6rl0Ynem7eBjq9u16vvA69tk4LEMWiSwW9MlbLdF3erE3vKn1mTc0bcB2NSCpz4wyHmSNHnzJkpzQXnd71qly+z+owOGmbHKYoDbwRVH4lnG6sX6BaL0KyvVZQA/ZsuRZhQigexMVx30TRhpuhDKmILyIgw6u7XGdjw85kPrUgRVr7vteq7rJg7HYEXiAvNgDirVCwq7EkddA62NUpWxZavKMrjAPY4iuz4cjv3YuvjLi16xK2aMxdSiTfZUFjdV+HjdLEde4D4skTi36ohPbQhulaopuwkTa1DmQb5D2YRIrptAYMBVwNfJrXLV/ksJCePtCdEl+csA6nK5+rzwqUt6KxLnVgWBrYkvvm3gDr0XiHWrlgJRHEGYXX/WZEHNWOY6mqCf7tZ1cavsl5nEEAcHnx9GEOyp36zqdnmBGHodk9x3t6jTiHGrhmc1oOQ1W98qLLj2PQxCCKPaRHIdY45D9FokIvWEnX0XiLMcS5uxiuLDAgmDkCAGDQ7HY0VE4sWRz2hF0vXVl4k7woJulSOaVEh179/LxotjD4PNbuUxGHEAxCGhhMXijsBYmUC3u9gpILH53T6rks5yJT92L5BqDLJ2q2u3qtBgU0CVmNBoo4gFCWITdxBtBKIQhzCLMfFLFLLbPnz7+pwwfEq3HgZjSbq2HFBcHCrKUmZEsRAV6E4RBiET5ogKUeIkijJbCgExyfg+ZsYhyXnXqj56L5KuxVHFrZrFxV61dq1cf6T1y5SQJbNYiDJUFsURumcG3oujXnoduHd9ZWWCcpbGrSqSsQKICHcWi5nl+SFRHGWKI0lMsDcd7ClPr7NbN0X0ka4vIkWhlK6CoITLEvfuIGZu21dsvUqVUJZEBXvrhRFEGnizUSOjy241QVnLsRQIS7pWE4Kt8yjKjCUshSgs3l4vCpstU/Fs8CKhzEBTiGfEtsaqaFBuMlapvqwoYSzMsHFHkYOlmC29UNrg2rtbxa1HSbfKYiYEU/MdqsQyq6cL/nyC3/SkHkbdCKIsQvG5A1UIiYmleMf6MAiJCJkHbA3gODSBObNlbdtElLkuTzWunbtVtMZKUGJmLAWIg0JliM61mhDBVkytxKEQhSarVRdhZL/4LFejXBt3q3j5uiJx8epcRxiEmXHHWhwVYo7cc4UB88BI2Tta9XFtU2JBIFoAABoSSURBVMBly9djmRWe60jWWWmi+bYCM0wxY13iCEMzx+7F0RzXMgVcuIwEW75eQiCmzspO6G0tK1az1LZOgUQQYhZc5ZY2+jRXY4zSkpTKWMmyVPk6AEG8M5Hn3LTCs4EFCMOAuW2bv+9vikNz2rmfWzyKa5HdKpKxMguflJDYpHQLCiQMQiOOQJknonLT3VFNvVZNAgnDAI0mZtDnCEQx4ghjWF1NiaLYZM48tTMaS1I0nVtmVaAjr84KNRN6UG9gvncxu60yltCc+PbVrfWvVhcLopJG0bPhWsYkaYo2XEhiBBKR3Ic9DmEWxUQNTFGEYUAUKJl53TgkXEbcmZ5x+6r+c3uyGYW7VSxA19JpXYIYUqsAnf9fY+ixhcmYZfxFCkQhp7emua+NopjYe1y1M3h3q/DkYByWEsl6IVT6DHGDCgE0CjL/pjBmr0AcpycLX0JfkdEF7qWWpCqlWveEQUigGQJBSyfCCp0zDAgj0Hm2QFSLxTznJxf1X5xneCIpIw4FiMN1sH6QICaITXPqdNGgC9TrqrkCI444iogmEBFsndKdL4xBZvFWgJ7m/OSC1cUC5n4hVhMMyt0qVdKuFK7adZYjc0LCTjbOls2UlmTNnbs1JqfTfGE4zi9ONntCeo5i0NmtMp+/SfPOiJbFGr+BXWOeMcriECKJKWqIDp7PlpaEEQSBZs6exyEIy4OWI4xgrgHnCV27cphoe+Nuz5H02pKUcauSe3kcmgNZl7Iz2bmTq/3qmjnUZT3iKLLn3I073Dmz5j7SrC4WZlIz2S/FNr47nd5iMYXLBxfeslRgcAWOhQWSsZfHIfLn6sxqwVonBrEd8ncqhLcFeShzdX5yYZo/bB3G+IK3z85YJF6+OD3Z31nbk8kgRFL65leiatdZj4jJzv6KLkUcB/UF5smqXcloghWHQBSymubPCrpslemMkq5gVAiXTE93rc50AQ8uFt7hKknvY5JSGSstXrXrGk5HiTt58kbMMmRmOyMGNcUe642HXNVuamzHMwiIuX0gMDcWyDlWm2KxcAmnt85YnNZzvZ799MKSFGmYvXZNKFe1m51BSqSsaiaMyIw7kufcF3OAiTvCCCZRMig3f/vV7cMZL29JqtFrd+ugSCrs5RHEbI+yzcFMm9Ca5zsAokAzt8oO7QKsfXGHc600mqTcM3O9q+nVVtyRx3Rh/vciKU/v3a1MrG9VZrUgQcyEgJ1muTb7FcVCUOdqwSBmHjlppBvOmXMGIdzeI5DTxQmxXcAlALJZZ397ekaBahSmC2OBTlfGzTtPXIPvC3wc/bQkruk05ZbSuqbTTS+GcuS1GnUbhK6uDo/u1eJi1z2zCYlbBUt9T04XOxk7110ylpmxqj7bdZDKlkREvhT4LeCp9vm/pKo/JiLPBd4CPAN4FPheVf28iDwVeDPwIuCPgO9R1Y8VvtISTaeTa8wjFZBoy01xTaerNH7LPae1HpEGBBmhTigxMts/17GusYpSmTYrjtXZGbduH76W6QIevDRu1WYdiWk+MZOYeM+OvZ7iHLQkIiLAV6jqn4vIU4DfBl4L/BDwK6r6FhH5j8DvqOodETkHvkFV/5mIvBL4LlX9ngPn0KpNp9N3yDJNp8sSRxGB7sY57pxBGB4URxxFTDRdRmLcKqBw3HG6ONk6zrrSOdidM8qbOPVsU0vgLiJfjhHJg8AC+BpV/aKI/C3gx1X1O0XkHfb7/y4iTwY+Adyte04kN29q+LpHi/81tun0zodesul0UcIwyN+azZ7zUJ3VanFBpKlui4l0cNZ8RxYn57vHcS7lvqRfZtm/Z4ujAncReRLGpXoe8DrgI8BnVPWL9imPA/fY7+8BPm5P+kUR+SzGJft03vHv+j/FBOJ6W+1OBlZrOr33XMk6qwm7VcF2riaY7ReIsx4PEmxt0ONWGd46nTJlv0CmC+uiWffMHcfFPstov0AA8/74jiqVKGtJbgC/ClwAb1TV59nH7wV+TVX/hoi8D3iJqj5uf/cRYKKqn04d6wHgAYCnfQ0veuV/zj/vOqWbqMlw2Z+w5hqr9TkjtuujHIrZm43DccfO9gg2W3f7rLhrtVhdmHUm6cl2MddQphwnqzTGs6G2eRIR+dfA/wV+mJrcrbvvE33FG7N/F0YwSRfpNuRWQX53RNfoOlwerrM6PVnsXvOeMpI8Llbbx0lOqJZeiszuZqWebSqLRETuBr6gqp8RkS8Dfh34SeBVwC8nAvf3quptEXkN8DcTgfvfV9Xv3neOLJGYNR7Rbo7fLsOte20HHF9nlRXYJ4P6IgKZLlz8kmqiZX2rY1ZGmto1304lj2NE8g3Am4AnYVYy/qKq/hsR+TpMCvjpwP8E/qmq/qVNGf8s8E3AHwOvVNWP7jtHUiTrptPb2VxU6i9fh83S2bz5DingWmWWr9uo/PYtI6xDrtViZTNfyVUm7u/GlM9UsR5JIkK/O9Yeel2W4kSSziDVvpdHClNnlZUaNXMNAYeXzZr9QTbX7F67upoWijkgMd+Rcs/Cim7VPvzEYj69F8mnP7C92Y1zceoWx7F1Vlvl6ztxcPG4w9VYnZ4sto6zb76jDrxI8um1SJJlKeuWoTSQscpdV76xHHDAtVpc7Pj1ajs5nt4qZj1OTnPcM8X0JuZ41yoPP7GYzwBE0sxeHo6YICPjtIk7ipSvp7NeZcrXwc53XF6y3XBiI46mhJHGTyxm0+sq4BdwF/e76twax0kYBrbw0QbDyWPbCl2Z5ZeSnJ9cpDq7b+QRxsKdW2cUqGE0ZSQnC4JLdmbcQ1kSSrvuj59YLEc/LMnd9yl5EyUVyV1XrqYncBTud6tOFydm19yUsBS4c1Y8KL84P8mYnzCZr6bijiL4icVd+u1u1SwSjSbphbqASQYcylhBdvm6SySUKV/fcc9sGUmTbVIP4SoXsjt+XW967W7VQRxFu/MrbNbEz5YQRPkCca5VNAEVU37uUtDMlqyubrE4IBBXY6V2N53trRqUWYtxR5p1E4xAkPz9sjwZjMKSZK0rT4ojOiAOwiijC2KF8vVUs+p1fVlNk4FVMBOI6bkcTxajc7fWpSQZ26XFNkNWpHx9rrs9eMV2ji9TRrKTVq2hjORowiijFZEnj9F0lXdNpueB7myXpmzijkPl66eLk60m1a65toQx09XVQYFMF6aU5PxyYY7jqgTsRYSy7EwgEWEi6eAFciyDsySZ68ptjZOEh3vo7vTqAVBleues0Pmni5wm1Yl1+V2xdq3SptVTiEEH7uuuJCnXCDi4RVqyjIToku1NBU28cJpqE5pFsoyE1BIRsaX7XQnEzaIH4EvhG6DXInGTgcEcSK3sW5egRyGnV/lZp+3K2k3h5Cy2XRCnZh3yPharCy4W2xW6ThwzWRJLd9YjiEEDX2bSJL11t/LqrIq263FdELezTWYt+HRVbK7DuVZp90zp1q0CJw5fXlIng8huba0rT2dlbDcVov1lJJDVBdEM7DvTw24VJNO5GU2qW66zShPZvdr9upD66X1Mso471vMdG9doSUiwrrHKFsjqYkEcLTK7IBIuuXNVLO5IdkHcWtcSh4RB+3VWjsi2SbJdKbxAWqQXluQ+uVs/yP9mp86KYtuiNdUFMXmcrvGVu83Tb3frpiiJrkJFihDzuiC6eKFIg+lNc+nLXfesB3VWESFhmLW4y9ME/RaJW3RVoF1PbhfERLueIZeROExg7mus2qTXIjE7XR3eFi2vC6Ir0jqqC6KC2DarXbJeOehbwbdOr0Vyn9yt/3w6yf392nqkq1dte6Gr1WHTke6CmFUG3xUuY+XF0S29Fsmzb9zQh+6/f+fxvF5WaPEuiC5jNc8yQNTXruco0ou7PJ0wOJFk1kdVaNdzsdqNO7CJgU6FgZ8Q7BuDEMnacmQsLY1LdkE8XZzsHMfNd/Qh7sjaBdjTLb0XyXe847PNdEG0hwHtdKYcEildv8ajl/RaJHLzpvLo9k7uZcpIYLe59OYoVG4wXSthlNnSyNMf+i2SrT0Ti+82u9UFMRV3LO3qxK7F4axH5kbAnl4xAJGYXlbHdUFkrZAu2/WAF8cQ6bVI7pb7dHL76ws9N7sLIlu7zXaNC8y9PIZFr6uAv/C1V8B+kezrghjP6Hy32eSE4ATpOgLy1EgvRHKIi/NEN0U7+tbl6xLi7t1dEcTAxMxWenGMj164WzeefUPvf2h3xv3kdEE0UVR2NxI9tNtsWxiB+MBjDPTa3UqyLl+/XIBAlGoTKsuQWdBdux5IrA5cd0T0jJleiSTpVp2nyuBDiZkJxCR8rg5I7+/hBTJ+euNu/cM/fEd2q9IjdputHT8hOGp6nQKWm6L6aHpntR60CbUY6xF4qzFy+h2TOIEkd5uVJd2t8DC4jojpxIHnetEPS+Jm3PviVuEaL4CPOq4P/bYkL7iL8IPdC2RrhaAXh8fSC0tyn9ytb+QVnV6Dme/wUfl1pt+WpEMiQuZqswMdNZ7z9JvB7U9SFxEhQWwmBEXwoYcnl+spkjBizsS2a/Tq8OznWonE7QBlSq28ODzFuBYica7V3O6S5eXhKcPoA/f1AqjAz5h7qjFKkSTnOwLfEdFzJKN0t8Iw2OyI6wXiOZJRiSSITTmJbxnqqZPBu1tr10oDjGflFeKpl0GLJLkAKvJulachhutuhZHZ190HHZ6GGZwlMWs8rGvlPStPCwzGkrjZ8jmB33zW0yqDsCSBzk3nlIqWw+1J0nwVvO8WP0Z6K5LkhGCl0a3rLyxnQiQxpPdbrA11p/IaGSG9FEkQQxyZOqsixkMBseNUlnZl/BLCwGz1FhHbx2b13utd+3pmhBISxZHpDeaFMip6tzKxbEdEt996FMWFnl/H0lzXnDuU5c7vfOOI4ZK3MrEXgfunuctU6jJHC5bpqppdc2UZFhYIgMSzjWtUGl2fM0sgAKEske7vO54a6YUluSk39VEePfg851ZhXaowqNZ0aK5BYZeoyjmjOMLXxgyPXq9xLyqQZWjanR6LiVsOD+J9btVhfKZrLPTC3TqEouvt3eo76D4Letit2kcYhEe4dJ6+0Qt3a3vPREsqW1XVtcojiiM02OzSW5crt3X8nX3oPX2m372A0yJJ7HvYJC7TdZxblY/PdA2LXme3ksQhrQgETKbrGLfqED7TNQ4KWxIReRLwCPCEqp6JyHOBtwDPAB4FvldVPy8iTwXeDLwI+CPge1T1Y3uPfVNUHzW7V0H9rlWX+EzXcKjDkrwW+EDi558EflpVnwf8CfBq+/irgT+xj/+0fd5e7nr0BWYPkqAdC9I+3pwMmUIiEZFnAVNs3lREBPhW4JfsU94E62a+L7c/Y3//bfb51xKf6Ro+RS3Jvwf+FfBX9udnAJ9R1S/anx8H7rHf3wN8HMD+/rP2+deX5Wx/xtnTaw6KRETOgE+p6uEZvxKIyAMi8oiIPPIXfKbOQ/eOMAhZHlMN4+mUIpbkm4G/JyIfwwTq3wr8B+CGiLgZ+2cBT9jvnwDuBbC//ypMAL+Fqj6sqjdV9eafv+gTJsAdMVEU+0zXQDkoElX9EVV9lqo+B3gl8Buq+k+A3wT+gX3aq4C32u/fZn/G/v439FAK7VFgEo1eKG6i0jMsjpkn+WHgh0TkMUzM8Xr7+OuBZ9jHfwh4qNDRBLOJzsjxscnw6NWMuwISjzUNbIgaWx3pOZZBzLgLoEFEGPZgX+qGCGXprcnA6JVIwHpdEaMWis90DYteuVtb2HW5Y3W9Ig38cpOeMQh3awuRcQfyPtM1GPorEgARIp2MNjXcAyPuKUB/3a0kI3W9fKarXwzP3Uoy0oHkM13DYBgiAXSkM/I+09V/huFuWVTtKsLRuV0+09UHhu1uWURGalF8pqvXDEokMNrwxMcmPWZQ7taalrqptInPdHXPKNytNbZ2ZUxul+nW0v0Ny7PLMEUCoxRKHIqXSQ8ZrkgABOKq21/1kCiK8TLpH8MWCSOsGLa9xzz9YfAiSZbWj8X16kEuxZNg8CIBI5SxNEkMgxBBvdPVI0YhEocG4yitD2XpY5MeMSqRCMKccZTW+0xXfxjmZOIBFNN8e+iTjRETfFFXe4xrMvEAo9kRxGe6esEoRQJAMB+F29UDQ3/tGaW7tUFh4G6X3y2rPa6Vu7VBBm9RfKare3ohkhdwV4NHH8E9OJ55mXRIL0Ry9VVfTkzY3ECYDLsrpJtg9HRDL0TyvKd8jlvTU5Y0FDsYr2vQbpfPdHVHL0QCcHmy4tb0tLn7pZg+w0MWii9W6YbeiASMUO5Mp42tPRIwJmWAhEHI0s/Cd0KvRALw4MkJzOLGhKKYrpBDxK836YbeiQRAiZjemTYyHARAZLiBvM90tU4vRQJwuTpp1PUKIgZpUXymq316KxIwrtfts+aEggw04+UzXa3Sa5GAEUpTrhcIOtAZeZ/pao/eiwSadb3ECmVI+ExXuwxCJLBxvZoJ5s1irSHhM13tMRiRgE0PNziHMji3y8cmrTAokQCcnd1uaI3F8CqGwyD0601aYHAiuTxZcXZn6oViWXpj0jiDEwmYQF4a265A0MlwRBKEoc90NUwvRPLYF7689Gs0AuJmhCIMpyukz3Q1Ty9E8rynfK7S66arq5qvxCKmK+RQ3C6f6WqWXoikMospYUO1kIIprR+KRfGZruYYtEguT1bMo7CxomHTPnU4d2if6WqGQYvEMY9Cmuq3gi2t77vrFQahz3Q1xChEAjC902QhpMCk36UrYRgwGZDVGxKjEcnlylYMNzYl38/FWlEcMdeASTSizpU9YzQigWbLVoBeldY7cWgQITKKxkm95cldX0DdTM/ucIk2dFcVdAIS02lXyEgnKIHfrLclRmVJwJat3D5r7PgidDYjH4YBcw1AxAukRUZnSQBYTCE+aWz7KxFQDZAW9pJfu3eTiLmA9MPbu1aMzpKAsSbTW6eNla2AEUrTGa8ojozVCiLwcUdnjFIkYISiEc0G8khjgXykEwjm3q3qAaMVyZpZ3Nyx7da/dQklik0ZzJzAmiqvkD4wepFMr1bETfUYhtqEEsURTCLnWXl6xOhFcnmyYjW9olG/68j4ZK4BdjbQ00NGLxKwbYlunzWqE5Vy8UkUR0Q6Ye7mO7xAesu1EAmYspXpnWljxy9aWh/FEXMmaBCZ+Y7GrshTF9dGJICZP2mwntyGJ7lCcXGH+CqrQdGLjUVv3n23PvKKV7RyrrOrUxaXD9JoblUVlmZDU+eC6cTPdfSdvI1FxznjvofLkxVnZ3e4pMEBa6bkCUNhHqi3HAPn2onEMSMGGlyaK8IEX74+Bq5XTGK5PFlxNV01WrYC3rUaC70RydnVaavnuzxZQRQ2XLbiGQO9Ecnlyar1cypRs2UrnlFQSCQi8jER+V0ReY+IPGIfe7qIvFNEPmz//2r7uIjIz4jIYyLyXhFp10SUZHq1gtALxZNPGUvyd1T1G1X1pv35IeBdqvp84F32Z4CXAs+3/x4A7tR1sU1webJienoL73d58jjG3Xo58Cb7/ZuAVyQef7MaYuCGiJwccZ7mWUwJWXZ9FZ6eUjQFrMCvi4gC/0lVHwaeqaquz+gngGfa7+8BPp547eP2sa2epCLyAMbS8LVPe1q1qz+Ss9MrpgtYXJ77VJQnl6IiuV9VnxCRvw68U0Q+mPylqqoVUGGs0B4GM+Ne5rXHcnZ1ysnilEsmZh7DC8Szh0IiUdUn7P+fEpFfBV4MfFJETlT1yrpTn7JPfwK4N/HyZ9nHOufs6pSTi3MuJ2ZS3C8X9xThYEwiIl8hIl/pvge+A3gf8DbgVfZprwLear9/G/B9NssVAJ9NuGWdcXZ6xeLynChotmzLMz6KWJJnAr8qZmQ9Gfh5Vf0vIvJu4BdF5NXAHwDfbZ//duBlwGPA54Dvr/2qS3B2dcriYgXBJZx7dXjKM8oqYDd7b8QxxwcdniJcmyrgO1dXnFwYt4oF+MjDcyyjEcmWW7XwlsNTH71wt0RuKjxSx5FqOIbnupLnbvVEJPJnwIe6vo4M7gI+3fVFpPDXVIyy1/RsVb076xd9cbc+lKgJ6w0i8kjfrstfUzHqvKbelMp7PH3Fi8TjOUBfRPJw1xeQQx+vy19TMWq7pl4E7h5Pn+mLJfF4ekvnIhGRl4jIh+xy34cOv6Kx6yi8RLnBa3iDiHxKRN6XeKzzZdI51/XjIvKEfb/eIyIvS/zuR+x1fUhEvrOB67lXRH5TRH5PRN4vIq+1jzfzXqlqZ/+AJwEfAb4O+BLgd4AXdnQtHwPuSj32b4GH7PcPAT/Z8DV8C3AKvO/QNWCKSH8NM4MaAMuWr+vHgX+Z8dwX2s/xqcBz7ef7pJqv5wQ4td9/JfD79ryNvFddW5IXA4+p6kdV9fPAWzDLf/tC3hLlRlDV3wL+uOA1tLZMOue68ng58BZV/UtV/V+YavAX13w9V6q6st//GfABzOrXRt6rrkWSt9S3C9wS5Uft0mLIX6LcJmWXSbfJD1j35Q0JV7TV6xKR5wDfBCxp6L3qWiR94n5VPcV0e3mNiHxL8pdq7HanqcA+XEOCO8DXA9+I6V/w79q+ABF5GvDLwA+q6p8mf1fne9W1SHqz1FcTS5SBrSXKAKklym2Sdw2dvneq+klV/X+q+lfAnI1L1cp1ichTMAL5OVX9FftwI+9V1yJ5N/B8EXmuiHwJ8ErM8t9WqbBEuU16uUw65dN/F+b9ctf1ShF5qog8F9N/7X/UfG4BXg98QFV/KvGrZt6rJrM1BTMVL8NkJz4C/GhH1/B1mIzM7wDvd9cBPAPTeO/DwH8Fnt7wdfwCxnX5AsZvfnXeNWAyNa+z79vvAjdbvq6fted9rx2EJ4nn/6i9rg8BL23geu7HuFLvBd5j/72sqffKz7h7PAfo2t3yeHqPF4nHcwAvEo/nAF4kHs8BvEg8ngN4kXg8B/Ai8XgO4EXi8Rzg/wPwe9lxB03F1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[FINAL] SalinasSeed3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
